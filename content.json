[{"title":"关于我","date":"2017-12-28T16:37:07.000Z","path":"2017/12/29/关于我/","text":"","tags":[]},{"title":"Make the .gitignore file work immediately","date":"2017-01-06T06:56:08.000Z","path":"2017/01/06/make-gitignore-e7-ab-8b-e5-8d-b3-e7-94-9f-e6-95-88/","text":"用过idea或者其他ide的人都知道。如果不想让一些test文件，或者ide配置文件一起上传到项目当中，我们用.gitignore来忽略这些文件。 但是有时候你会发现，没有建.gitignore之前，那些需要忽略的文件已经提交了，这时，即使把新建的.gitignore文件提交了，也无法让已经上传上去的文件撤下来。 我们可以用下面简单的三行命令解决这个问题，核心思想就是重新add。 git rm -r --cached . git add . git commit -m &#39;update .gitignore&#39;","tags":[]},{"title":"apache segmentation fault","date":"2016-10-30T13:11:55.000Z","path":"2016/10/30/apache-segmentation-fault/","text":"今天外包的一个项目突然崩了，显示“服务器未发送任何数据”（err empty response），之前遇到这种情况一般是自己的代码写错了，然后没有正常输出数据。但是代码上线一年多，而且都由我来维护，不可能是代码的问题。 首先ping域名发现ip是对的而且能ping通，那就排除了服务器域名dns的问题。 然后登上服务器，第一步先用top，发现负载为0，内存、io也木有问题。 第二步检查一下apache的状态，发现进程正常运行，端口也正常绑定。所以直接先重启apache。 ps aux | grep &quot;httpd&quot;//查看进程 netstat -an | grep &quot;:80&quot;//查看网络监听 /etc/init.d/httpd restart //重启apache`&lt;/pre&gt; 然后网站就能正常访问了。**基本确定是apache的问题了。** 于是第三步从apache的日志入手。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`tail -f /etc/httpd/logs/error_log `&lt;/pre&gt; 结果如下图，出现一大堆的segmentation fault，也是本文的标题。 [![apache segmentation fault](http://blog.djmgod.cn/wp-content/uploads/2016/10/QQ图片20161030204012-300x82.png)](http://blog.djmgod.cn/2016/10/apache-segmentation-fault.html/qq%e5%9b%be%e7%89%8720161030204012) 上网google了一下，比较靠谱的说法是因为**php的zend模块**引起的。 我确实部署了一个xcache来加速php，于是去他的bug report里面找，终于发现有类似的bug爆出。**还发现使用了加速php这类的zend扩展都会有引起apache段错误的问题**。 最后我**卸载了xcache**，然后业务暂时回复正常。 **我的思考：**由于xcache+PHP+Apache这个方案已经运行了一年多了，期间也只是出现xcache的oom问题，所以我怀疑问题可能不是出自xcache，或者还有其他的原因，如果要追根到底的话，可以对httpd进行调试，由于是线上环境，而且我的空余时间不是很多，就没有再去尝试了。读者可以自己检验。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`gdb httpd","tags":[]},{"title":"static的作用","date":"2016-10-06T16:19:27.000Z","path":"2016/10/07/static-e7-9a-84-e4-bd-9c-e7-94-a8/","text":"上一篇文章c的5种储存类有说到static，这篇文章总结一下static的作用。 static关键字至少有下列n个作用：（1）设置变量的存储域，函数体内static变量的作用范围为该函数体，不同于auto变量，该变量的内存只被分配一次，因此其值在下次调用时仍维持上次的值； （2）限制变量的作用域，在模块内的static全局变量可以被模块内所用函数访问，但不能被模块外其它函数访问； （3）限制函数的作用域，在模块内的static函数只可被这一模块内的其它函数调用，这个函数的使用范围被限制在声明它的模块内； 以下是C++对static的扩展（4）在类中的static成员变量意味着它为该类的所有实例所共享，也就是说当某个类的实例修改了该静态成员变量，其修改值为该类的其它所有实例所见；（5）在类中的static成员函数属于整个类所拥有，这个函数不接收this指针，因而只能访问类的static成员变量。","tags":[]},{"title":"c的5种储存类","date":"2016-10-06T14:05:27.000Z","path":"2016/10/06/c-e7-9a-845-e7-a7-8d-e5-82-a8-e5-ad-98-e7-b1-bb/","text":"在c语言里面，用于储存程序数据的内存可用存储时期、作用域、链接来表征。 储存时期可以是静态的、自动的或者分配的。如果是静态的，内存在程序开始执行的时候被分配，并在程序运行时一直存在。如果是自动的，变量所用的内存在程序执行到该变量定义的 代码块时开始分配，在退出代码时，自动释放。如果是程序员自己分配的（malloc或者其他相关函数）内存，通过free（）释放。作用域决定了哪一部分程序可以访问某个数据。在所有函数之外定义的变量具有问津啊作用域，并对该变量声明之后定义的全部函数可见。在代码块里面定义或者作为函数参数定义的变量具有代码块作用域，并只在该代码块及其子代码块中可见。 链接描述了程序的某个单元定义的变量可被链接到其他的哪些地方。具有代码块作用域的变量作为局部变量，具有空链接。具有文件作用域的变量可有内部链接或外部链接。内部链接意味着变量只可在包含变量定义的文件内部使用，外部链接意味着变量可以在其他文件中使用。 下面是5种存储类： 自动—-在一个代码块内(或在一个函数头部作为参量)声明的变量，无论有没有储存类修饰符auto，都属于自动储存类，该类具有自动储存时期、代码块作用域和空链接。若未经初始化，他的值是不定的。 寄存器—-在一个代码块内(或在一个函数头部作为参量)使用储存类修饰符register声明的变量属于寄存器储存类。把一个变量声明为寄存器变量可以指示编译器提供可用的最快访问（根据系统情况选择存放在寄存器还是高速内存，你无法获取他的地址）。在其他许多方面，和auto类一样。 静态、空链接—-在一个代码块内使用储存类修饰符static声明的变量属于静态空链接储存类。该类拥有静态储存时期、代码块作用域和空链接，仅在编译的时候初始化一次。如未明确初始化，所有的字节都被设定为0. 静态、外部链接—-在所有函数外部定义、未使用static声明的变量属于静态、外部链接储存类。该类拥有静态储存时期、代码块作用域和外部链接，仅在编译的时候初始化一次。如未明确初始化，所有的字节都被设定为0. 静态、内部链接—–在所有函数外部定义、使用了static声明的变量属于静态、外部链接储存类。该类拥有静态储存时期、代码块作用域和外部链接，仅在编译的时候初始化一次。如未明确初始化，所有的字节都被设定为0. &nbsp;","tags":[]},{"title":"进程与线程","date":"2016-10-06T06:32:17.000Z","path":"2016/10/06/e8-bf-9b-e7-a8-8b-e4-b8-8e-e7-ba-bf-e7-a8-8b/","text":"面试的时候又问到，自己总结了一下。仅供参考。进程定义进程是进程实体的运行过程，是系统仅从资源分配和调度的一个独立单位。进程几种基本状态1、就绪2、阻塞3、执行进程转换过程1、就绪-&gt;执行 进程调度（获得cpu资源和时间片）2、执行-&gt;就绪 时间片完3、执行-&gt;阻塞 i/o请求4、阻塞-&gt;就绪 i/o完成pcb（Process Control Block）的作用1、pcb是系统感知进程存在的唯一标志2、因为进程切换时会把cpu的现场保存在pcb，实现了间断性运行方式3、保存了进程管理所需要的信息。保存了内存和外存的始址指针、文件、i/o设备等进程运行的全部资源4、提供进程调度所需要的信息。保存了状态信息、优先级、等待时间、已执行时间等5、实现与其他进程的同步与通讯。保存了用于同步的信号量、用于进程通讯的区域或通信队列指针等。pcb存的信息1、进程标识符 1、外部标识符 用户自己定义的 2、内部标识符 os赋予的唯一数字id2、处理机状态 1、通用寄存器 2、指令计数器 3、程序状态字psw（条件码、执行方式、中断屏蔽标志等） 4、用户栈指针3、进程调度信息 1、进程状态 2、进程优先级 3、进程调度算法有关，hrrn（Highest Response Ratio Next）高响应比优先调度算法，需要等待时间、运行时间等参数 4、事件。是指发生进程转换的原因4、进程控制信息 1、程序与数据的地址 2、同步与通讯的所需的信息，消息队列指针、信号量 3、资源清单。除cpu外的进程运行所需资源，还有一张已分配给该程序的资源清单 4、链接指针。下一个进程pcb的首地址。进程ipc1、管道2、消息队列3、共享内存4、信号5、socket 线程与进程的比较1、线程是调度和分派的基本单位，是能独立运行的基本单位。2、进程之间可以并发，线程之间也能并发。3、进程是资源分配的基本单位，线程本身不拥有系统资源，它仅保存了tcb、一组寄存器和栈。同一进程的线程共享相同的地址空间。4、进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。5、线程切换和撤销都比进程快。7、在多线程OS中，进程不是一个可执行的实体。*线程控制块tcb1、线程id2、一组寄存器，程序计数器PC、状态寄存器、通用寄存器（都是副本）3、线程运行状态4、优先级5、线程专用储存区，用于线程切换时存放cpu现场。6、信号屏蔽7、堆栈（栈）指针，局部变量和返回地址。2个指针，一个指向用户栈，一个指向系统栈。","tags":[]},{"title":"分布式一致性算法","date":"2016-09-04T07:28:53.000Z","path":"2016/09/04/e5-88-86-e5-b8-83-e5-bc-8f-e4-b8-80-e8-87-b4-e6-80-a7-e7-ae-97-e6-b3-95/","text":"一、强一致性R+W&gt;N，建设有3个节点，每次读时，读2个节点并且数据一致；写时，写2个节点都成功才算写成功。这种是强一致性。 2PC，3PC 多个节点都成功时，才算成功，否则进行回滚操作。 PAXOS，类似于2PC,解决分布式系统如何就某个值（决议）达成一致，进行投票选举。是一种无主的节点的算法。分布式的协调服务zookeeper就实现了这个算法，保障一致性。mongodb中的集群方案replicaset也实现了类似的算法。 二、弱一致性由于分布式系统在数据同步时的网络延迟等等因素，无法保证副本数据和主节点时刻保持一致，当出现不一致的时，可以采用以下几种策略保证最终一致性 Gossip（Cassandra，Dynamo），是带冗余容错算法，也就是最终一致性的算法，无法保证某时刻所有节点数据一致，它是一个去中心化的部署方式，集群中每个节点维护一组状态，状态可以用key,value，外带一个版本号表示，版本大的比版本小的数据新，节点之间相互交流数据的版本信息，并更新数据，类似病毒式的传递，这样数据可以达到最终一致。Cassandra就是采取这种策略来进行数据的同步,并且维护节点的健康状态。 Raft: 在一个由 Raft 协议组织的集群中有三类角色： Leader（领袖） Follower（群众） Candidate（候选人）就像一个民主社会，领袖由民众投票选出。刚开始没有领袖，所有集群中的参与者都是群众，那么首先开启一轮大选，在大选期间所有群众都能参与竞选，这时所有群众的角色就变成了候选人，民主投票选出领袖后就开始了这届领袖的任期，然后选举结束，所有除领袖的候选人又变回群众角色服从领袖领导。这里提到一个概念「任期」，用术语 Term 表达。 Leader选举阶段 1、至少有三个Candidate，因为要保证其中一个能获得多数票。 2、所有Candidate启动随机的定时器，timeout后，Candidate会先投自己一票，然后向其他人发送拉票申请。 3、Candidate收到其他人的拉票请求后，在没有投过票的情况下，给最早到达的拉票投票。 4、当一个Candidate获得多数票后，会宣布自己当选Leader，然后item+1，如果，没有一个节点当选，则执行随机退让算法，重新启动随机器，进行新的一轮投票，直到一个Candidate当选为止。 一致性的保证 1、client先向Leader发请求，Leader向所有Follower广播，当Leader收到半数的ack后，才向client回复ack。 2、保证Leader拥有最新的数据，当一个Follower挂掉回复以后，会接受Leader的日志同步。 3、当Leader挂掉以后，然后经过一定的心跳时间都没有回复的话，会进行新的选举，选出的新leader的任期要加1. 4、如果挂掉的Leader在选举期间的拉票请求广播被其他Candidate收到的时候，先检查任期，比当前任期小的Candidate一律不投票。 问题 1、脑裂问题，如果出现物理的网络分区现象，Leader存在的分区如果还是多数票则不会重新选举。新分区节点大于2会进行Leader选举。因此出现双Leader。但新分区的Leader的任期会比原Leader新，所以当网络恢复的时候，原Leader发现新的Leader的任期比自己新，会降级为Follower重新同步数据。","tags":[]},{"title":"Mysql 扩展字段的设计","date":"2016-08-25T03:19:14.000Z","path":"2016/08/25/mysql-e6-89-a9-e5-b1-95-e5-ad-97-e6-ae-b5-e7-9a-84-e8-ae-be-e8-ae-a1/","text":"如果有大量的内容不好新建一个固定的字段，那我们可以采用扩展字段的方式来增加扩展性。一般我们存储大量kv字符串会采用序列化例如“123||345||567”。但是我们可以修改一下存储的形式，“||123||345||567||”缺点：序列化后需要在两边补上分隔符，反序列化需要先删除两边的分隔符。（程序级别）优点：可以方便like操作 ，例如我要获取扩展字段含有345的项。可以使用like %||345||%。（sql检索级别）","tags":[]},{"title":"Redis各种数据类型的使用场景","date":"2016-08-18T09:35:28.000Z","path":"2016/08/18/redis-e5-90-84-e7-a7-8d-e6-95-b0-e6-8d-ae-e7-b1-bb-e5-9e-8b-e7-9a-84-e4-bd-bf-e7-94-a8-e5-9c-ba-e6-99-af/","text":"既然题目的是数据类型的使用场景。所以一些基本概念我就不说了。 一、String&nbsp; 1、利用INCR命令簇（INCR, DECR, INCRBY）来把字符串当作原子计数器使用。 2、使用APPEND命令在字符串后添加内容。 3、将字符串作为GETRANGE 和 SETRANGE的随机访问向量。 4、在小空间里编码大量数据，或者使用 GETBIT 和 SETBIT创建一个Redis支持的Bloom过滤器。 5、键值不宜过长，耗内存、查找成本高。 二、List1、Redis的List采用linked list实现。在头部或尾部插入效率为常数级别。 2、可以采用lpush、rpop实现一个简单的消息队列，用rpoplpush命令把要出队的元素放入处理队列队尾，直到确认完成后，用lrem移除。 3、如果rpoplush的source和destination都是同一队列，此时便是旋转队列操作，可以模拟循环队列，用于多个客户端并行处理消息。 4、使用lpush与ltrim保持列表长度，可以用于热点数据的保存。 5、博客的评论可以按发表时间进入列表，使用lrange进行分页。 6、使用lpop的阻塞版本blpop，可以防止客户端轮询消耗server的cpu资源。 三、Hash1、Redis的hash用作kv存储时，内存占用优于memcached的kv。 2、可以存储游戏的人物的属性，例如user:1000 nickname jack age 21 四、Set1、由于Redis的set是没有重复元素的，所以可以用于元素的排重。 2、使用sinter求集合的交集，可以用于博客文章标签库的设计。 eg : tag1 1 2 5 tag2 2 4 6 tag3 2 6 7 //三个标签存储着属于该标签的博客id sinter tag1 tag2 tag3 2 //最后得到同时拥有三个标签的博客id 3、使用sunionstore可以快速的copy一个set。 4、使用spop可以随机pop出一个元素，用于设计需要产生随机数的系统，例如扑克牌游戏。如果不想元素出集合，使用srandmember可以仅仅返回元素（随机）。此时返回的元素可能是重复的。 五、Softed set1、内部的实现为跳跃表和hash表，所以添加元素的时间复杂度为O(log(n)). 2、可以用于排名榜系统，用zrange获取前n名的names，然后用zrank name获得排名。 3、使用zrangebyscore、zremrangebyscore可以检索或移除指定区间内的元素。 六、bitmap1、底层使用string来实现。大大地提高了利用效率，1byte=8bit。原本只能存512Mbyte的string现在能放2^32个bit。 2、bitcount可以用于大数据的区间计算。例如计算一天最长的访客区间，从00:00开始，每一个unix时间取偏移值setbit，最后bitcount。 3、用于大数据的实时分析。 七、HyperLogLogs1、用于大数据的允许误差的基数运算，用set实现的区别为，HyperLogLogs并不会储存具体的元素，不管元素有多少，最坏情况下只需12kbyte就能完成运算，误差为1%。例如用户每天的搜索量。 八、参考【1】data-types-intro","tags":[]},{"title":"Redis-vs-Memcached-vs-MongoDB","date":"2016-08-16T07:48:24.000Z","path":"2016/08/16/redis-vs-memcached-vs-mongodb/","text":"一、前言redis、memcached、mongodb这个三个系统现在使用广泛。做一个后端工程师对他们必然要有一定的认识，下面我翻译了一个图表进行简单说明。 二、正文名称MemcachedMongoDBRedis简述全内存的kv存储, 最初设计用于缓存最流行的文档型数据库全内存的结构数据存储，可用于数据库，缓存，消息代理。Redis专注于性能，所以它的很多设计都把高性能、低延迟放在第一位。数据库模型k-v 存储文档型数据库k-v存储众多的数据类型、丰富的操作集、可配置的数据过期时间，历史数据回收和数据持久官网www.memcached.orgwww.mongodb.orgredis.io技术文档github.com/­memcached/­memcached/­wikidocs.mongodb.org/­manualredis.io/­documentation开发者Danga InteractiveMongoDB, IncSalvatore Sanfilippo初次发布200320092009最新发行版1.4.29, July 20163.2.8, July 20163.2.3, August 2016证书BSD开源协议AGPL 第三版开源协议， 提供商业版证书BSD 3-条款，提供商业版证书数据库服务不提供不提供不提供实现语言CC++C支持的服务器端osFreeBSDLinuxOS XUnixWindowsLinuxOS XSolarisWindowsBSDLinuxOS XWindows数据模式schema-freeschema-freeschema-free数据类型没有string, integer, double, boolean, date, object_id支持的数据类型：strings, hashes, lists, sets and sorted sets, bit arrays, hyperloglogs and geospatial indexesXML 支持不第二索引不支持支持不支持SQLnononoAPIs 和其他通信协议专有协议 使用 JSON专有协议客户端支持的语言.NetCC++ColdFusionErlangJavaLispLuaOCamlPerlPHPPythonRubyActionscript （非官方）CC#C++Clojure（非官方）ColdFusion（非官方）D（非官方）Dart（非官方）Delphi（非官方）ErlangGo（非官方）Groovy（非官方）HaskellJavaJavaScriptLisp（非官方）Lua（非官方）MatLab（非官方）PerlPHPPowerShell（非官方）Prolog（非官方）PythonR（非官方）RubyScalaSmalltalk （非官方）CC#C++ClojureCrystalDDartElixirErlangFancyGoHaskellHaxeJavaJavaScript (Node.js)LispLuaMatLabObjective-COCaml（非官方）PerlPHPPrologPure DataPythonRRebolRubyRustScalaSchemeSmalltalkTcl服务器端脚本不支持JavaScriptLua触发器nonono分区方式没有分区分片分片副本方式Repcached（高可用方案）主从复制主从复制接入MapReduce不支持支持不支持一致性最终一致、实时一致最终一致外键不支持通常不使用不支持事务不支持在同一的Document里面提供原子性乐观锁，命令具有原子性并发支持支持支持，数据序列化存储持久化不支持支持（可选）支持（RDB、AOF）数据存在内存 支持3.2以后支持支持用户鉴权使用 SASL (Simple Authentication and Security Layer) 协议基于角色的权限控制RBAC（Roles-based Access Control）基于用户密码的认证，商业版支持ssl和访问控制 三、小结通过上面表格应该大致了解三个系统的大致区别，不过这只是皮毛，以后我会去更多去探讨他们在一致性，副本、持久化方面的实现来进一步了解他们的设计理念。 四、摘录【1】System Properties Comparison Memcached vs. MongoDB vs. Redis","tags":[]},{"title":"一致性Hash算法","date":"2016-07-28T07:34:52.000Z","path":"2016/07/28/e4-b8-80-e8-87-b4-e6-80-a7hash-e7-ae-97-e6-b3-95/","text":"为什么我们需要一致性Hash一致性哈希算法在1997年由麻省理工学院的Karger等人在解决分布式Cache中提出的，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得DHT可以在P2P环境中真正得到应用。 简单hash算法普遍采用： hash(o) mod n 但是当中间的一个节点挂掉时，我们的hash算法就变成下面这样 hash(o) mod (n+1) 增加节点也是一样。 hash(o) mod (n-1) 由此可见，大量的请求将会偏移到新的机器。这会导致大量的缓存失效。一致性hash的出现就是为了解决这个问题而出现的。它保证当机器出现增删的时候，受影响的对象要尽可能地少。 ## Hash环 通常，hash函数把一个值映射成一个32位的键值，现在我们把0到2的32次方－1的值映射到一个环上面去，2^32-1下一个值就是0。如下图 ![hash环](http://www.codeproject.com/KB/recipes/lib-conhash/circle.JPG) ## 把对象映射到hash环里面 现在我们有4个对象Object1-Object4，使用hash函数获得hash值映射到hash环里面。如下图。 ![对象映射到hash环](http://www.codeproject.com/KB/recipes/lib-conhash/object.JPG) hash(object1) = key1; ..... hash(object4) = key4;` ## 把缓存机器映射进Hash环 使用相同的hash函数把cacheABC加进hash环。如下图。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`hash(cache A) = key A; .... hash(cache C) = key C; &nbsp; 对象与Cache的映射以上图为例，key1往顺时针方向移动，最后key1对应cacheA。key2、key3一起对应cache3. 增加或者剔除Cache当cacheB挂掉的情况下 ，原本缓存在cacheB的object4无法命中，顺时针重新缓存在cacheC。 当增加一台cacheD的情况下，原本缓存在cacheC的object2重新缓存到cacheD上。 虚拟节点如果节点较少的情况下，当一个节点的变动会导致大量的对象落到另外一个节点上，导致负载不均，为了解决这个问题。我们提出了虚拟节点的概念。 我们现在拥有两个cache，每一个cache拥有一个副本，每次增加或删除节点，我们都增加或对应多的节点副本。如下图。 我们有了一下的对应关系 objec1-&gt;cache A2; objec2-&gt;cache A1; objec3-&gt;cache C1; objec4-&gt;cache C2那么object怎么通过虚拟节点找到实际节点的。如下图。 有了虚拟节点，我们的hash算法的平衡性就增加了。 参考资料1、Consistent-hashing ： http://www.codeproject.com/Articles/56138/Consistent-hashing","tags":[]},{"title":"用explain命令分析mysql性能","date":"2016-07-28T02:33:36.000Z","path":"2016/07/28/e7-94-a8explain-e5-91-bd-e4-bb-a4-e5-88-86-e6-9e-90mysql-e6-80-a7-e8-83-bd/","text":"explain显示了mysql如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。 使用方法，在select语句前加上explain就可以了： 如： explain select surname,first_name form a,b where a.id=b.id EXPLAIN列的解释：table：显示这一行的数据是关于哪张表的 type：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、indexhe和ALL possible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句 key： 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MYSQL会选择优化不足的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MYSQL忽略索引 key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好 ref：显示索引的哪一列被使用了，如果可能的话，是一个常数 rows：MYSQL认为必须检查的用来返回请求数据的行数 Extra：关于MYSQL如何解析查询的额外信息。将在表4.3中讨论，但这里可以看到的坏的例子是Using temporary和Using filesort，意思MYSQL根本不能使用索引，结果是检索会很慢 extra列返回的描述的意义Distinct:一旦MYSQL找到了与行相联合匹配的行，就不再搜索了 Not exists: MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行，就不再搜索了 Range checked for each Record（index map:#）:没有找到理想的索引，因此对于从前面表中来的每一个行组合，MYSQL检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一 Using filesort: 看到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行 Using index: 列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候 Using temporary 看到这个的时候，查询需要优化了。这里，MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上 Where used 使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型ALL或index，这就会发生，或者是查询有问题不同连接类型的解释（按照效率高低的顺序排序） system 表只有一行：system表。这是const连接类型的特殊情况 const:表中的一个记录的最大值能够匹配这个查询（索引可以是主键或惟一索引）。因为只有一行，这个值实际就是常数，因为MYSQL先读这个值然后把它当做常数来对待 eq_ref:在连接中，MYSQL在查询时，从前面的表中，对每一个记录的联合都从表中读取一个记录，它在查询使用了索引为主键或惟一键的全部时使用 ref:这个连接类型只有在查询使用了不是惟一或主键的键或者是这些类型的部分（比如，利用最左边前缀）时发生。对于之前的表的每一个行联合，全部记录都将从表中读出。这个类型严重依赖于根据索引匹配的记录多少—越少越好 range:这个连接类型使用索引返回一个范围中的行，比如使用&gt;或&lt;查找东西时发生的情况 index: 这个连接类型对前面的表中的每一个记录联合进行完全扫描（比ALL更好，因为索引一般小于表数据） ALL:这个连接类型对于前面的每一个记录联合进行完全扫描，这一般比较糟糕，应该尽量避免","tags":[{"name":"mysql","slug":"mysql","permalink":"http://superdjm.github.io/tags/mysql/"}]},{"title":"keepalive（前端高可用）初探","date":"2016-07-27T08:14:12.000Z","path":"2016/07/27/keepalive-ef-bc-88-e5-89-8d-e7-ab-af-e9-ab-98-e5-8f-af-e7-94-a8-ef-bc-89-e5-88-9d-e6-8e-a2/","text":"一、前言在大型网站架构中，我们常常会部署nginx、haproxy、lvs等反向代理进行负载均衡。 可是单点的nginx总是会出现故障，我们就有了keepalive、zookeeper等维护反向代理集群，实现前端高可用。 本文要用的是nginx+keepalive，nginx的负载均衡在这也不展开了。主要介绍一下keepalive的选举机制；VRRP。 虚拟路由冗余协议(Virtual Router Redundancy Protocol，简称VRRP)是由IETF提出的解决局域网中配置静态网关出现单点失效现象的路由协议 VRRP的工作过程如下： 路由器开启VRRP功能后，会根据优先级确定自己在备份组中的角色。优先级高的路由器成为主用路由器，优先级低的成为备用路由器。主用路由器定期发送VRRP通告报文，通知备份组内的其他路由器自己工作正常；备用路由器则启动定时器等待通告报文的到来。 VRRP在不同的主用抢占方式下，主用角色的替换方式不同：l在抢占方式下，当主用路由器收到VRRP通告报文后，会将自己的优先级与通告报文中的优先级进行比较。如果大于通告报文中的优先级，则成为主用路由器；否则将保持备用状态。l在非抢占方式下，只要主用路由器没有出现故障，备份组中的路由器始终保持主用或备用状态，备份组中的路由器即使随后被配置了更高的优先级也不会成为主用路由器。 如果备用路由器的定时器超时后仍未收到主用路由器发送来的VRRP通告报文，则认为主用路由器已经无法正常工作，此时备用路由器会认为自己是主用路由器，并对外发送VRRP通告报文。备份组内的路由器根据优先级选举出主用路由器，承担报文的转发功能我们下面就来实战一下。 二、正文一、安装keepalive使用包管理工具yum或者apt来获取keepalive，或者可以上网下载源码包，自己make编译。这里就不贴出来了。 二、配置因为主备的配置都大同小异，所以注意以下的不同之处即可。 /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { #这一部分配置报警的通知邮箱 notification_email { #zhouxiao@example.com #itsection@example.com } #notification_email_from itsection@example.com #smtp_server mail.example.com #smtp_connect_timeout 30 #名字 router_id NGINX_DEVEL } #进行心跳脚本的配置 vrrp_script chk_nginx { # script &quot;killall -0 nginx&quot; script &quot;/etc/keepalived/check_nginx.sh&quot; interval 2 weight -5 fall 3 rise 2 } vrrp_instance VI_1 { #配置主从机，MASTER为主，BACKUP为从。 state BACKUP #要监控的接口 interface eth0 # mcast_src_ip 172.17.0.7 #id，所有主备机要保持一致 virtual_router_id 51 #选举时成为主机的优先级，配置时每台主备机要配置不一样的值 priority 100 #组播信息发送间隔，保持一致 advert_int 2 #VRRP的鉴权，所有主备机要保持一致 authentication { auth_type PASS auth_pass 1111 } #要绑定的虚拟vip，所有主备机要保持一致 virtual_ipaddress { 172.17.0.6 } #对应上面的脚本的配置 track_script { chk_nginx } }`&lt;/pre&gt; 心跳脚本/etc/keepalived/check_nginx.sh &lt;pre class=&quot;pure-highlightjs&quot;&gt;`#!/bin/bash #检测nginx的进程数，如果为0，休眠两秒不能恢复，主动停止keepalive进程。 counter=$(ps -C nginx --no-heading|wc -l) if [ &quot;${counter}&quot; = &quot;0&quot; ]; then /usr/local/bin/nginx sleep 2 counter=$(ps -C nginx --no-heading|wc -l) if [ &quot;${counter}&quot; = &quot;0&quot; ]; then /etc/init.d/keepalived stop fi fi`&lt;/pre&gt; &amp;nbsp; 配置就到此结束。 ### 三、结果观察 开启keepalive服务。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`root@c56be86de341:~#``keepalive -D root@c56be86de341:~# ip addr 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 9: eth0: &amp;lt;BROADCAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:04 brd ff:ff:ff:ff:ff:ff inet 172.17.0.4/16 scope global eth0 valid_lft forever preferred_lft forever inet &lt;span style=&quot;color: #ff0000;&quot;&gt;172.17.0.6&lt;/span&gt;/32 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::42:acff:fe11:4/64 scope link valid_lft forever preferred_lft forever `&lt;/pre&gt; 主（172.17.0.4）已经成功绑定vip。ping通。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`vagrant@supin:~$ ping 172.17.0.6 PING 172.17.0.6 (172.17.0.6) 56(84) bytes of data. 64 bytes from 172.17.0.6: icmp_seq=1 ttl=64 time=0.057 ms 64 bytes from 172.17.0.6: icmp_seq=2 ttl=64 time=0.035 ms 64 bytes from 172.17.0.6: icmp_seq=3 ttl=64 time=0.046 ms 64 bytes from 172.17.0.6: icmp_seq=4 ttl=64 time=0.035 ms 64 bytes from 172.17.0.6: icmp_seq=5 ttl=64 time=0.041 ms ^C --- 172.17.0.6 ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 3999ms rtt min/avg/max/mdev = 0.035/0.042/0.057/0.011 ms`&lt;/pre&gt; kill掉主机的keepalive。查看备机的ip状态。vip已经成功漂移到备机（172.17.0.9）。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`root@778a812a82b0:~# ip addr 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 15: eth0: &amp;lt;BROADCAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:09 brd ff:ff:ff:ff:ff:ff inet 172.17.0.9/16 scope global eth0 valid_lft forever preferred_lft forever inet &lt;span style=&quot;color: #ff0000;&quot;&gt;172.17.0.6&lt;/span&gt;/32 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::42:acff:fe11:9/64 scope link valid_lft forever preferred_lft forever 验证成功。 三、小结上面我们搭建的是keepalive的主从模式，这样会导致永远只有一台主机处于访问状态。 还有一种模式叫双主模式，允许两台机器均处于工作状态并互相作为备份。 搭建keepalived双主模式的要素： 1、必须有两个虚拟IP, 分别绑定至两个节点上 2.、每个节点作为某个虚拟IP的主节点，并同时作为另外一个虚拟IP的备用节点。 3.、当某个节点产生故障时，两个虚拟IP自动绑定至正常节点上","tags":[]},{"title":"Mongoose在创建Model时对Collection的命名策略","date":"2016-07-25T11:56:03.000Z","path":"2016/07/25/mongoose-e5-9c-a8-e5-88-9b-e5-bb-bamodel-e6-97-b6-e5-af-b9collection-e7-9a-84-e5-91-bd-e5-90-8d-e7-ad-96-e7-95-a5/","text":"最近在使用express+mongoose+jade搭建一个小小的node.js应用。 mongoose是node里面作为mongodb的orm的api层。使用mongoose的schema、model，可以很方便的以面向对象的方式对mongodb进行curd操作。 首先创建一个schema，定义你的collection。我创建的是一个follow表，里面存放着微信粉丝的一些信息。 /schema/follow.js var mongoose = require(&#39;mongoose&#39;); var Schema = mongoose.Schema; //在这定义followschema的结构 var FollowSchema = new Schema({ subscribe : { type : Number, default : 0}, nickname : String, openid : String, sex : Number, headimgurl : String, country : String, province : String, city : String, }); //在这里定义schema的静态方法 FollowSchema.statics = { findByOpenid : function (openid, cb) { return this. findOne({openid : openid}) .exec(cb); } } module.exports = FollowSchema;`&lt;/pre&gt; /model/follow.js &lt;pre class=&quot;pure-highlightjs&quot;&gt;`var mongoose = require(&#39;mongoose&#39;); var FollowSchema = require(&#39;../schema/follow&#39;); //进行model的编译 var Follow = mongoose.model( &#39;Follow&#39;, FollowSchema ); module.exports = Follow;`&lt;/pre&gt; app.js &lt;pre class=&quot;pure-highlightjs&quot;&gt;`var mongoose = require(&#39;mongoose&#39;); function connectDb() { mongoose.connect(&#39;mongodb://localhost/test&#39;); var db = mongoose.connection; db.on(&#39;error&#39;, console.error.bind(console, &#39;... connection error ...&#39;)); db.once(&#39;open&#39;, function callback() { console.info(&quot;... db open ...&quot;); }); } var _follow = new Follow({ subscribe : data.subscribe, nickname : data.nickname, openid : data.openid, sex : data.sex, headimgurl : data.headimgurl, country : data.country, province : data.province, city : data.city, }); _follow.save(function(err, _follow) { if (err) { throw err; } console.log(_follow); }) 通过model的save方法就完成了数据的插入。 当我用命令行连上mongo的时候，用db.follow.find()并没有找到任何项，那就奇怪了。命名起的是这个名字，怎么就找不到了。当我输入show collections的时候，出现了一个名叫follows的colloection，竟然被强制加上复数形式。。 然后我就发现了一篇很好的文章，从源码的角度对这个问题进行了解释，附上链接。 我在下面简单的概括一下，就是mongoose的作者在创建colloection的时候，会根据你定义的单词进行正则匹配，判断是可数名词还是不可数，如果是可数名词的话，再判断它的复数形式，然后替换成她们的复数形式。源码在mongoose/lib/util.js。 &nbsp;","tags":[]},{"title":"node.js 热部署（监听文件修改自动重启node服务）","date":"2016-07-25T10:01:18.000Z","path":"2016/07/25/node-js-e7-83-ad-e9-83-a8-e7-bd-b2-ef-bc-88-e7-9b-91-e5-90-ac-e6-96-87-e4-bb-b6-e4-bf-ae-e6-94-b9-e8-87-aa-e5-8a-a8-e9-87-8d-e5-90-afnode-e6-9c-8d-e5-8a-a1-ef-bc-89/","text":"一、前言在写php的时候，代码更改，也不用去重启我们的webServer，想dump个什么东西，在线上都能做。 刚接触node，每一次更改代码都要重启node服务。大大降低了工作效率。 这是因为 Node.js 只有在第一次引用到某部份时才会去解析脚本文件，以后都会直接访问内存，避免重复载入，而 PHP 则总是重新读取并解析脚本(如果没有专门的优化配置)。Node.js的这种设计虽然有利于提高性能，却不利于开发调试，因为我们在开发过程中总是希望修改后立即看到效果，而不是每次都要终止进程并重启。 这时若你修改了js文件，或是调试功能，或是增加功能。这时需要重新发布该服务，每次修改都需要执行以下两步： 1 control+c 2 node server.js 很不爽！因此有人开发了一个自动发布（热发布）的工具，你只需要在修改文件后保存，它就能自动替你发布，这就是所谓的热部署。就像tomcat或websphere等一些主流的web应用服务器那样保存即热部署。下面将介绍几个NodeJS中的开源热部署工具。 二、工具介绍一、supervisor跟docker的进程管理工具名字一样有木有。 Node Supervisor is used to restart programs when they crash. It can also be used to restart programs when a *.js file changes.`&lt;/pre&gt; supervisor是用于node进程崩溃时重启node，它也可以用于监听后缀为js文件的改变而重启node。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`//全局安装supervisor npm install -g supervisor //执行命令 supervisor server.js`&lt;/pre&gt; 然后我们就可以愉快地更改代码了。不过这个工具有一个特点。当你的代码不能启动的时候，你的console台就会不断刷出报错的信息，因为他失败重试启动node服务的间隔很短，且没有错误次数累计。 有一个比较重要的参数，可以设置什么时候不重启node。 &lt;pre&gt;`-n|--no-restart-on error|exit|success Don&#39;t automatically restart the supervised program if it ends. Supervisor will wait for a change in the source files. If &quot;error&quot;, an exit code of 0 will still restart. If &quot;exit&quot;, no restart regardless of exit code. If &quot;success&quot;, no restart only if exit code is 0.`&lt;/pre&gt; ### 二、hotnode 这个工具与supervisor的用法是一样的。 然后它会在重启时打出一条日志说明是哪几个文件产生了修改。 ### 三、forever github地址： [https://github.com/nodejitsu/forever](https://github.com/nodejitsu/forever) forever是一个简单的命令式nodejs的守护进程，能够启动，停止，重启App应用。forever完全基于命令行操作，在forever进程之下，创建node的子进程，通过monitor监控node子进程的运行情况，一旦文件更新或进程挂掉，forever会自动重启node服务器，确保应用正常运行。 &lt;pre&gt;`//全局安装 npm install forever -g //启动 forever start app.js //关闭 forever stop app.js //输出日志和错误 forever start -l forever.log -o out.log -e err.log app.js //自动监控文件变化，文件修改保存之后自动重启app.js forever -w app.js //查看帮助 forever -h `&lt;/pre&gt; 前面的supervisor和hotnode都有一个严重的问题，无论是用nohup或者在命令最后加上&amp;amp;也不能保持后台持续运行，一旦ssh断开了，程序也就关闭了。亲测forever很好用，既能keeplive也可以热部署。 ### 四、pm2（支持node集群） github地址：[https://github.com/Unitech/pm2](https://github.com/Unitech/pm2) 告别node-forever，拥抱pm2: [http://se77en.cc/2013/06/27/goodbye-node-forever-hello-pm2-translation/](http://se77en.cc/2013/06/27/goodbye-node-forever-hello-pm2-translation/) &lt;pre&gt;`npm install -g pm2 pm2 start app.js -i max //启动一个使用所有CPU核心的集群 pm2 list //列出所有pm2开启的进程 pm2 monit pm2 logs //打印日志`&lt;/pre&gt; 看上去很强大，没有用过。mark。 ### 五、\bgrunt 今天看慕课发现使用grunt也可以达到自动部署的作用。 首先安装这几个包 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`npm install grunt -g npm install grunt-cli -g npm install grunt-contrib-watch --save-dev npm install grunt-nodemon --save-dev npm install grunt-concurrent --save-dev`&lt;/pre&gt; `grunt-contrib-watch 是用于监视文件变化重启node服务的。` `grunt-nodemon是用于后台运行node的。` `grunt-concurrent适用于grunt插件的并行运行。` 然后参考一下配置文件gruntfile.js &lt;pre class=&quot;pure-highlightjs&quot;&gt;`module.exports = function(grunt) { grunt.initConfig({ watch: { //监听的项目 jade: { files: [&#39;views/**&#39;], options: { livereload: true } }, js: { files: [&#39;public/js/**&#39;, &#39;models/**/*.js&#39;, &#39;schemas/**/*.js&#39;], //tasks: [&#39;jshint&#39;], options: { livereload: true } } }, nodemon: { dev: { options: { //后台守护的进程 file: &#39;bin/www&#39;, args: [], ignoredFiles: [&#39;README.md&#39;, &#39;node_modules/**&#39;, &#39;.DS_Store&#39;], watchedExtensions: [&#39;js&#39;], watchedFolders: [&#39;./&#39;], debug: true, delayTime: 1, env: { PORT: 3000 }, cwd: __dirname } } }, concurrent: { tasks: [&#39;nodemon&#39;, &#39;watch&#39;], options: { logConcurrentOutput: true } } }) grunt.loadNpmTasks(&#39;grunt-contrib-watch&#39;) grunt.loadNpmTasks(&#39;grunt-nodemon&#39;) grunt.loadNpmTasks(&#39;grunt-concurrent&#39;) grunt.option(&#39;force&#39;, true) grunt.registerTask(&#39;default&#39;, [&#39;concurrent&#39;]) } 最后在项目目录输入grunt。搞掂。 &nbsp;","tags":[]},{"title":"kafka初探","date":"2016-07-19T07:35:26.000Z","path":"2016/07/19/kafka-e5-88-9d-e6-8e-a2/","text":"一、简介Kafka是一种高吞吐量的分布式发布订阅消息系统。kafka相关术语 Broker Kafka集群包含一个或多个服务器，这种服务器被称为broker Topic 每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处） Partition Partition是物理上的概念，每个Topic包含一个或多个Partition. Producer 负责发布消息到Kafka broker Consumer 发布消息通常有两种模式：队列模式（queuing）和发布-订阅模式(publish-subscribe)。队列模式中，consumers可以同时从服务端读取消息，每个消息只被其中一个consumer读到；发布-订阅模式中消息被广播到所有的consumer中。Consumers可以加入一个consumer 组，共同竞争一个topic，topic中的消息将被分发到组中的一个成员中。同一组中的consumer可以在不同的程序中，也可以在不同的机器上。如果所有的consumer都在一个组中，这就成为了传统的队列模式，在各consumer中实现负载均衡。如果所有的consumer都不在不同的组中，这就成为了发布-订阅模式，所有的消息都被分发到所有的consumer中。更常见的是，每个topic都有若干数量的consumer组，每个组都是一个逻辑上的“订阅者”，为了容错和更好的稳定性，每个组由若干consumer组成。这其实就是一个发布-订阅模式，只不过订阅者是个组而不是单个consumer。 Consumer Group每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。2个kafka集群托管4个分区（P0-P3），2个消费者组，消费组A有2个消费者实例，消费组B有4个。 Kafka的保证(Guarantees) 生产者发送到一个特定的Topic的分区上的消息将会按照它们发送的顺序依次加入 消费者收到的消息也是此顺序 如果一个Topic配置了复制因子( replication facto)为N， 那么可以允许N-1服务器宕机而不丢失任何已经增加的消息 二、环境的搭建Step 1: 下载Kafka 点击下载最新的版本并解压. tar -xzf kafka_2.11-0.10.0.0.tgz cd kafka_2.10-0.10.0.0`&lt;/pre&gt; **Step 2: 启动服务** Kafka用到了Zookeeper，所有首先启动Zookper，下面简单的启用一个单实例的Zookkeeper服务。可以在命令的结尾加个&amp;amp;符号，这样就可以启动后离开控制台。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/zookeeper-server-start.sh config/zookeeper.properties &amp;amp; [2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)`&lt;/pre&gt; &lt;div class=&quot;blockcode&quot;&gt; 现在启动Kafka:&lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_CSP&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-server-start.sh config/server.properties [2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties) [2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)`&lt;/pre&gt; &lt;/div&gt; **Step 3: 创建 topic** 创建一个叫做“test”的topic，它只有一个分区，一个副本。&lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_SyW&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test`&lt;/pre&gt; &lt;/div&gt; 可以通过list命令查看创建的topic:&lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_wnh&quot;&gt;&lt;/div&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-topics.sh --list --zookeeper localhost:2181 test`&lt;/pre&gt; 除了手动创建topic，还可以配置broker让它自动创建topic. **Step 4:发送消息.** Kafka 使用一个简单的命令行producer，从文件中或者从标准输入中读取消息并发送到服务端。默认的每条命令将发送一条消息。 运行producer并在控制台中输一些消息，这些消息将被发送到服务端：&lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_WBM&quot;&gt; &amp;nbsp; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test This is a messageThis is another message`&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; ctrl+c可以退出发送。 **Step 5: 启动consumer** Kafka also has a command line consumer that will dump out messages to standard output. Kafka也有一个命令行consumer可以读取消息并输出到标准输出： &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_W2Z&quot;&gt;&lt;/div&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning This is a message This is another message `&lt;/pre&gt; 你在一个终端中运行consumer命令行，另一个终端中运行producer命令行，就可以在一个终端输入消息，另一个终端读取消息。 这两个命令都有自己的可选参数，可以在运行的时候不加任何参数可以看到帮助信息。 **Step 6: 搭建一个多个broker的集群** 刚才只是启动了单个broker，现在启动有3个broker组成的集群，这些broker节点也都是在本机上的： 首先为每个节点编写配置文件&lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_u7S&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`cp config/server.properties config/server-1.properties cp config/server.properties config/server-2.properties`&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; 在拷贝出的新文件中添加以下参数： &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_apw&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`config/server-1.properties: broker.id=1 port=9093 log.dir=/tmp/kafka-logs-1 `config/server-2.properties: broker.id=2 port=9094 log.dir=/tmp/kafka-logs-2&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt;broker.id在集群中唯一的标注一个节点，因为在同一个机器上，所以必须制定不同的端口和日志文件，避免数据被覆盖。 We already have Zookeeper and our single node started, so we just need to start the two new nodes: 刚才已经启动可Zookeeper和一个节点，现在启动另外两个节点：&lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt;&lt;/div&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-server-start.sh config/server-1.properties &amp;amp; bin/kafka-server-start.sh config/server-2.properties &amp;amp;`&lt;/pre&gt; 创建一个拥有3个副本的topic: &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_hDN&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic`&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; 现在我们搭建了一个集群，怎么知道每个节点的信息呢？运行“&quot;describe topics”命令就可以了： &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_H9p&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic`&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_uiM&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`Topic:my-replicated-topic PartitionCount:1 ReplicationFactor:3 Configs: Topic: my-replicated-topic Partition: 0 Leader: 1 Replicas: 1,2,0 Isr: 1,2,0`&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; 下面解释一下这些输出。第一行是对所有分区的一个描述，然后每个分区都会对应一行，因为我们只有一个分区所以下面就只加了一行。 &lt;span style=&quot;color: #ff0000;&quot;&gt;leader&lt;/span&gt;：负责处理消息的读和写，leader是从所有节点中随机选择的. &lt;span style=&quot;color: #ff0000;&quot;&gt;replicas&lt;/span&gt;：列出了所有的副本节点，不管节点是否在服务中. &lt;span style=&quot;color: #ff0000;&quot;&gt;isr&lt;/span&gt;：是正在服务中的节点. 在我们的例子中，节点1是作为leader运行。 向topic发送消息： &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_vU2&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic `my test message 1my test message 2^C&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; 消费这些消息： &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_ks3&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic ` my test message 1 my test message 2 ^C&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_mGM&quot;&gt; 测试一下容错能力.Broker 1作为leader运行，现在我们kill掉它： &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_nNl&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`ps | grep server-1.properties7564 ttys002 0:15.91 /System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/bin/java... kill -9 7564`&lt;/pre&gt; &lt;/div&gt; 另外一个节点被选做了leader,node 1 不再出现在 in-sync 副本列表中：&lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_PGA&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-topics.sh --describe --zookeeper localhost:218192 --topic my-replicated-topic Topic:my-replicated-topic PartitionCount:1 ReplicationFactor:3 Configs: Topic: my-replicated-topic Partition: 0 Leader: 2 Replicas: 1,2,0 Isr: 2,0`&lt;/pre&gt; &lt;/div&gt; 虽然最初负责续写消息的leader down掉了，但之前的消息还是可以消费的：&lt;/div&gt; &lt;div class=&quot;blockcode&quot;&gt; &lt;div id=&quot;code_Dft&quot;&gt; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic my test message 1 my test message 2 看来Kafka的容错机制还是不错的。 三、使用场景 ### 消息kafka更好的替换传统的消息系统，消息系统被用于各种场景（解耦数据生产者，缓存未处理的消息，等），与大多数消息系统比较，kafka有更好的吞吐量，内置分区，副本和故障转移，这有利于处理大规模的消息。根据我们的经验，消息往往用于较低的吞吐量，但需要低的端到端延迟，并需要提供强大的耐用性的保证。在这一领域的kafka比得上传统的消息系统，如的ActiveMQ或RabbitMQ的。### 网站活动追踪kafka原本的使用场景：用户的活动追踪，网站的活动（网页游览，搜索或其他用户的操作信息）发布到不同的话题中心，这些消息可实时处理，实时监测，也可加载到Hadoop或离线处理数据仓库。每个用户页面视图都会产生非常高的量。### 指标kafka也常常用于监测数据。分布式应用程序生成的统计数据集中聚合。### 日志聚合使用kafka代替一个日志聚合的解决方案。### 流处理kafka消息处理包含多个阶段。其中原始输入数据是从kafka主题消费的，然后汇总，丰富，或者以其他的方式处理转化为新主题，例如，一个推荐新闻文章，文章内容可能从“articles”主题获取；然后进一步处理内容，得到一个处理后的新内容，最后推荐给用户。这种处理是基于单个主题的实时数据流。从0.10.0.0开始，轻量，但功能强大的流处理，就进行这样的数据处理了。除了Kafka Streams，还有Apache Storm和Apache Samza可选择。### 事件采集事件采集是一种应用程序的设计风格，其中状态的变化根据时间的顺序记录下来，kafka支持这种非常大的存储日志数据的场景。### 提交日志kafka可以作为一种分布式的外部提交日志，日志帮助节点之间复制数据，并作为失败的节点来恢复数据重新同步，kafka的日志压缩功能很好的支持这种用法，这种用法类似于Apacha BookKeeper项目。","tags":[]},{"title":"docker容器ssh直连","date":"2016-06-20T08:10:43.000Z","path":"2016/06/20/docker-e5-ae-b9-e5-99-a8ssh-e7-9b-b4-e8-bf-9e/","text":"docker容器ssh直连 made by DJM op87960@gmail.com 具体实现 使用docker commit，先进入容器安装ssh之后进行容器的commit然后使用export导出到tar包供其他人下载。好处是可见即可得。缺点是要基于已存在的容器才能操作。 使用Dockerfile， 使用指令直接基于镜像来实现镜像的构建。缺点是要学习指令。本教程基于dockerfile。 一份很好的docker中文指南： Docker —— 从入门到实践 查看dockerfile的内容$cat /data/dockerfile/Dockerfile # This dockerfile uses the supin image with new sshd service ######## # V1.0 # ######## FROM supin:v1.0 MAINTAINER DJM &amp;lt;op87960@gmail.com&amp;gt; #install sshd RUN apt-get update &amp;amp;&amp;amp; apt-get install -y openssh-server &amp;amp;&amp;amp; apt-get clean #make dir for sshd&#39;s running RUN mkdir /var/run/sshd #add sshd to supervisord COPY supervisord-sshd.conf /etc/supervisor/conf.d/ #cover the config &quot;PermitRootLogin yes&quot; to ssh with root COPY sshd_config /etc/ssh/ #change passwd for root #I did it here just for test,you can create ur own ssh-user when you are running your container which is building by this dockerfile. RUN echo &quot;root:supin123&quot; | chpasswd #expose port 22 to the host EXPOSE 22 #init CMD [&quot;/run.sh&quot;]s 进入dockerfile所在目录$cd /data/dockerfile 基于dockerfile构建镜像$sudo docker build -t supin-ssh:v1.0 . 基于镜像运行容器，注意修改这里ssh的映射端口 －p host:container$sudo docker run -idt --name test -p 2200:22 supin-ssh:v1.0 最后ssh链接容器$ssh root@127.0.0.1 -p 2200 最后贴上附件下载","tags":[]},{"title":"vagrant实现mysql集群（主从复制）","date":"2016-05-19T14:51:26.000Z","path":"2016/05/19/vagrant-e5-ae-9e-e7-8e-b0mysql-e9-9b-86-e7-be-a4-ef-bc-88-e4-b8-bb-e4-bb-8e-e5-a4-8d-e5-88-b6-ef-bc-89/","text":"上次学会了vagrant的基本配置之后，我终于可以有机会去尝试我的php框架（RandomPHP）db的主从分离了，说是集群，我们在这里就开启两个拥有相同版本的mysql和nginx的虚拟机box来做。道理是一样的。 用Vagrant实现集群启示很简单，只需要简单的配置一下Vagrantfile。 Vagrant.configure(2) do |config| #config开头的配置会应用到所有虚拟机，即全局配置 config.vm.synced_folder “~/Public/htdocs”, “/var/www”,type: “nfs” #这里用define定义我们的第一台虚拟机 config.vm.define “web4” do |web4| #名称 web4.vm.box = “centos” #web4的网络配置 web4.vm.network “private_network”, ip: “192.168.50.4” end #第二台虚拟机的配置 config.vm.define “web5” do |web5| web5.vm.box = “centos2” #这里要注意我们分配另外一个ip web5.vm.network “private_network”, ip: “192.168.50.5” endend到这里我们就完成配置保存，然后vagrant up。等待虚拟机都开启后，开始我们今天最重要的主从复制了。 part1 主mysql 进入web4，vagrant ssh web4 ，编辑/etc/my.cnf，在[mysqld]段（注意此处很重要）加入下面这一段 #开启二进制日志log-bin=master-binlog-bin-index=master-bin.index #主服务器id，唯一，默认为1，一般取ip段的最后一位server-id=5然后我们进入mysql，输入show master status;查看状态. mysql&gt; show master status;+——————-+———-+————–+——————+——————-+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+——————-+———-+————–+——————+——————-+| master-bin.000006 | 120 | | | |+——————-+———-+————–+——————+——————-+1 row in set (0.00 sec)记下这里的file名（master-bin.000006）,还有这里的position（120）是数据位偏移，也先记起来。 然后为备份的从机创建复制帐号。 mysql&gt; grant replication slave on . to ‘repl’@’192.168.50.%’;mysql&gt; exitpart2 从服务器 进入web5，vagrant ssh web5，先修改/etc/my.cnf,在[mysqld]增加下面这段 #从服务器不需要开启二进制日志 #从机的idserver-id=4保存退出，然后进入mysql。 mysql&gt; change master to master_host=’192.168.50.4’, &gt; master_user=’repl’, &gt; master_password=’’, &gt; master_log_file=’master-bin.000006’, &gt; master_log_pos=0;//\b这里的偏移位如果是0的话，意味着开启复制线程，会先把之前存在的数据也复制过去。mysql&gt; start slave;mysql&gt; show slave status\\G //主要观察到这两个值是yes，复制线程就正常工作了。 Slave_IO_Running: Yes Slave_SQL_Running: Yesps：如果跟随我的操作的话。应该会出现 Fatal error: The slave I/O thread stops because master and slave have equal MySQL server UUIDs; these UUIDs must be different for replication to work.找到原因在于，由于两个虚拟机的mysql是一摸一样的，把数据文件里面auto.cnf文件也拷贝过来了，里面记录了数据库的uuid，每个库的uuid应该是不一样的。 所以我们这里可以选择删除这个文件或者更改里面的uuid值就可以了。 我的mysql的data目录是/var/lib/mysql rm -rf /var/lib/mysql/auto.cnfservice mysqld restart问题得以解决。然后我们就可以去测试主从复制了。 到此，教程就结束了，其实用vagrant配置多台虚拟机来集群耗费的资源太多，本文仅作功能实现用，下次我将介绍用vagrant+docker实现集群，请期待。","tags":[]},{"title":"初入vagrant","date":"2016-05-11T09:46:19.000Z","path":"2016/05/11/e5-88-9d-e5-85-a5vagrant/","text":"进入速聘实习后，第一个遇到的是开发环境配置。他们使用的是vagrant+docker部署。先说说vagrant吧。 Vagrant可以为你提供可配置、可再生、便携的工作环境，它主要是一个中间层技术，它的下层是VirtualBox, VMware, AWS或者其他provider，它的上层是provisioning工具，比如shell scripts, Chef, or Puppet等可以自动化安装和配置软件的工具。所以它就是一个虚拟机！ 对于开发人员来说，Vagrant可以帮你统一团队成员的开发环境。如果你或者你的伙伴创建了一个Vagrantfile，那么你只需要执行vagrant up就行了，所有的软件都会安装并且配置好。团队成员可以通过相同的Vagrantfile来创建他们的开发环境，无论他们是在Linux, Mac OS X, 或者Windows下，这样就可以保证你团队成员的代码是跑在相同的环境中，从而避免令人烦躁的【在我的机器上是可以的】问题。 对于运维人员来说，Vagrant可以给你提供一次性，并且与线上一致的服务器环境，你可以利用VirtualBox或者VMware来测试你的shell scripts, Chef cookbooks, Puppet modules等管理脚本。你不需要再苦逼的登录到线上服务器提心吊胆的测试了，Vagrant可以解救你。 对于设计人员来说，Vagrant可以帮你处理一切，你只需要专注在设计上就好了。一旦开发人员帮你配置好了Vagrant之后，你只需要执行vagrant up，然后开始设计。它的使用也很简单，首先下载vbox和vagrant。然后就是你的box，就是你的vbox镜像，选择你想要的环境。 然后cd到你的box目录。开始我们的vagrant之路。 vagrant box add you_name xxx.box //在vbox加入你的boxvagrant init you_name //生成Vagrantfilevim Vagrantfile在Vagrant里面我们进行一些必要的配置。 1：网络配置（config.vm.network） 1.1：public_network 虚拟机使用与宿主机同一个网段，外网也可以访问。（桥接网络） 1.2：private_network 虚拟机使用一个特定的ip，宿主机作为路由器，仅内网访问。 1.3：hostly-only （默认）虚拟机使用127.0.0.1环回。仅内网访问 2：文件夹共享（config.vm.synced_folder） 2.1：“宿主目录”, “虚拟机目录” 3：自动化部署工具（config.vm.provision） 2.1：chef 2.2：puppet 3.2：shell # config.vm.provision “shell”, inline: &lt;&lt;-SHELL sudo apt-get updatesudo apt-get install -y apache2SHELL4：端口映射（config.vm.network）网络为hostly－only时有效 4.1 “forwarded_port”, guest: 3306, host: 3306 当我们配置好Vargrantfile后。就可以启动vagrant了，仅需要轻轻敲下 vagrant up然后视机器性能等待启动。 启动后有些常用的命令要说明 vagrant ssh //ssh到虚拟机上面去，其实这里我们可以使用自己的工具，账号密码都是vagrant。vagrant reload //重启虚拟机，重载配置，当你修改了vagrantfile的内容时需要使用。vagrant halt //关闭虚拟机。vagrant suspend //挂起虚拟机vagrant status //查看虚拟机状态vagrant destroy //销毁虚拟机 介绍几个坑或者优化的地方 Q：使用共享文件夹时出现文件权限的问题，提示权限不足。 A：因为虚拟机挂载时采用了宿主机的默认权限，所以我们可以通过在配置里面制定挂载的权限。 config.vm.synced_folder “/Users/bob/Documents/code/“, “/var/www/“, :mount_options =&gt; [“dmode=755”,”fmode=644”]Q：访问速度很慢？？ A：可以采用nfs挂载共享目录的形式。上面的权限问题也可以解决了。 config.vm.synced_folder “./www”, “/var/www”,type: “nfs”Q：运行时提示不能分配内存？？ A：我曾经试过安装nginx的时候跳出这个问题，我free了一下，发现总内存果然很少。 然后查了一下，默认分配的内存时512M，现在大家的内存都上4G了，我们可以考虑提高这个值。 config.vm.provider “virtualbox” do |vb| # Display the VirtualBox GUI when booting the machinevb.gui = true # # Customize the amount of memory on the VM: vb.memory = “1024” end一定要注意删除注释的地方。","tags":[]},{"title":"php耗时任务解决方案","date":"2016-04-19T13:30:19.000Z","path":"2016/04/19/php-e8-80-97-e6-97-b6-e4-bb-bb-e5-8a-a1-e8-a7-a3-e5-86-b3-e6-96-b9-e6-a1-88/","text":"之前的项目中，遇到了一个需求。 我们有10000多会员，我需要给他们赠送卡券（写库）并调用微信接口（curl请求微信api）来进行消息推送。 没有做优化之前，整个过程需要半小时。然后，down了。。。 谷哥之后，第一个采用的是使用php的set_time_limit()来延长脚本执行时间。这个对于脚本执行时间比较短还是可以勉强解决的。半小时实在超出了人类可忍耐的极限。 然后我又找到一对方法，popen和pclose。 ** Opens process file pointer @link http://php.net/manual/en/function.popen.php @param string $command &lt;p&gt; The command &lt;/p&gt; @param string $mode &lt;p&gt; The mode &lt;/p&gt; @return resource a file pointer identical to that returned by fopen, except that it is unidirectional (may only be used for reading or writing) and must be closed with pclose. This pointer may be used with fgets, fgetss, and fwrite. &lt;/p&gt; &lt;p&gt; If an error occurs, returns false. @since 4.0 @since 5.0*/function popen ($command, $mode) {} /** Closes process file pointer @link http://php.net/manual/en/function.pclose.php @param resource $handle &lt;p&gt; The file pointer must be valid, and must have been returned by a successful call to popen. &lt;/p&gt; @return int the termination status of the process that was run. @since 4.0 @since 5.0*/function pclose ($handle) {} 他们用于开启一个新进程管道来执行系统命令。于是有了以下的代码 pclose(popen(‘curl -m 1800 http://xxx.php &amp;’, ‘r’)); 第一个参数是命令‘curl’来访问xxx.php(进行与微信api的交互工作，此部分耗时最长)。 第一个是访问模式‘r’以只读的方式。 命令之后添加‘&amp;’的目的是让脚本在后台运行，于是popen会立即返回，然后我们使用pclose关闭这个管道。此时我们可以直接返回数据给浏览器，结束这次交互，然后耗时脚本就会后台安安静静地运行了。","tags":[]},{"title":"stack与heap的区别","date":"2016-04-06T07:05:38.000Z","path":"2016/04/06/stack-e4-b8-8eheap-e7-9a-84-e5-8c-ba-e5-88-ab/","text":"在腾讯的笔试题遇到了这个问题，当时就只知道数据结构中的堆和栈。。 part1 预备知识 一个由C/C++编译的程序占用的内存分为以下几个部分 1、栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。 2、堆区（heap） — 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式是采取链表形式分配。 3、全局区（静态区）（static）—，全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 - 程序结束后由系统释放 4、文字常量区 —常量字符串就是放在这里的。 程序结束后由系统释放 5、程序代码区—存放函数体的二进制代码。part2 代码介绍 //stack &amp;amp; heap int a = 0;//存放在全局变量区 void sampleStackAndHeap(){ static int b; //存放在静态变量区 char str[] = &quot;1234&quot;; //str存在stack中，为指针常量，“1234”是字符串常量，所以存放在文字常量区。 char *str = (char*)malloc(1); //str存放在stack中，malloc申请的1字节内存在heap分配。 Derived Obj ＝ new Derived(); //new 的对象内存在heap中分配。obj还是在stack中。 } part3 他们的结构 1、stack是由系统预定义的。是一块连续的内存。不能扩展，由系统自动申请和销毁。地址是从高位到低位递减。若栈满，则overflow。 2、heap是由程序员自己申请与释放的，用链表管理，是不连续的内存空间，容量由系统的虚拟内存决定。地址由低位向高位分配。 part4 存放的内容。 stack： 进入主函数之后，先把第一个可以执行的语句入栈。然后是函数的参数（一般编译器是从右到左入栈），最后是局部变量。执行完毕顺序出栈。 heap： 一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。","tags":[]},{"title":"我的php mvc之路系列(二) 配置加载类","date":"2016-04-02T13:31:56.000Z","path":"2016/04/02/e6-88-91-e7-9a-84php-mvc-e4-b9-8b-e8-b7-af-e7-b3-bb-e5-88-97-e4-ba-8c-e9-85-8d-e7-bd-ae-e5-8a-a0-e8-bd-bd-e7-b1-bb/","text":"今天要分享的是配置加载类。实现多级目录的数组形式的配置获取. &amp;lt;?php $config = new Config(__DIR__); var_dump($config[&#39;key&#39;]);`&lt;/pre&gt; 为什么我们能用$config[&#39;&#39;key]？？对象的数组访问？？ 没错。因为我们实现了[ArrayAccess接口](http://php.net/manual/en/class.arrayaccess.php)。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`ArrayAccess { abstract public offsetExists ( mixed $offset )//isset($object[&#39;name&#39;])时候调用 abstract public offsetGet ( mixed $offset )//var_dump($object[&#39;name&#39;])时候调用 abstract public offsetSet ( mixed $offset , mixed $value )//$object[&#39;name&#39;]=&#39;shiki&#39;时候调用 abstract public offsetUnset ( mixed $offset )//unset($object[&#39;name&#39;])时候调用 }`&lt;/pre&gt; 当运行到$config[&quot;key&quot;]的时候会自动访问offsetGet，然后直接在这个方法里面处理逻辑（**例如require你的配置文件，注意这里我们实现了延时加载配置文件。**）就可以了。 那么我们要require的配置文件究竟长什么样？ &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php $config = Array( &#39;router&#39; =&amp;gt; Array( &#39;Home\\\\&#39; =&amp;gt; &#39;djm&#39; ), &#39;database&#39;=&amp;gt;Array( &#39;type&#39;=&amp;gt;&#39;mysqli&#39;, &#39;host&#39;=&amp;gt;&#39;localhost&#39;, &#39;username&#39;=&amp;gt;&#39;root&#39;, &#39;password&#39;=&amp;gt;&#39;&#39;, &#39;database&#39;=&amp;gt;&#39;randomphp&#39;, &#39;port&#39;=&amp;gt;&#39;3306&#39; ) ); return $config;`&lt;/pre&gt; &amp;nbsp; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php if (file_exists($file_path)) { $config = require $file_path; }`&lt;/pre&gt; 我们的$config就获取我们配置文件里面的数组了，是不是很简单！ 下面说一下多级目录配置。 因为我实现的mvc里面有全局配置，模块配置，还有基于具体模块的配置 一开始的想法是让优先级高的配置覆盖优先级低的配置。可是一直想不到如何自动获取调用config类的当前目录路径，所有我最后的实现是使用一个二位数组存放不同path下的配置，然后程序运行到那个位置就通过设置一个成员变量path来获取对应path的配置。然后如果在优先级高的配置中找不到会继续往优先级低的配置寻找。如果在最低一层配置（全局配置）中也找不到，就返回空字符串。 大大的不妥。关于我对多级目录的配置的实现大家不要太在意～～ 所以我们这篇文章主要讲了“如何像数组一样访问你的php对象”的一个小技巧（通过实现ArrayAccess接口）。 最后贴出我整个类的源代码 。（仅供参考，请勿用于生产环境。） &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php namespace Random; /** * Class Config * @package Random * @author DJM &amp;lt;op87960@gmail.com&amp;gt; * @todo 配置类 * @example * $config = new Config(__DIR__); * var_dump($config[&#39;key&#39;]); */ class Config implements \\ArrayAccess { protected $path; protected $configs = array(); static $instance; function __construct($path) { $this-&amp;gt;path = $path; } static function getInstance($path) { if (!isset(self::$instance)) { self::$instance = new self($path); } else { self::$instance-&amp;gt;path = $path; } return self::$instance; } private function getConfig($path) { $file_path = $path . &#39;/Config/Config.php&#39;; $config = array(); if (file_exists($file_path)) { $config = require $file_path; } $this-&amp;gt;configs[$path] = $config; } function offsetGet($key) { //当前目录配置是否加载,否则先加载配置 if (!isset($this-&amp;gt;configs[$this-&amp;gt;path])) { $this-&amp;gt;getConfig($this-&amp;gt;path); } //检查当前目录配置是否存在此key if (key_exists($key, $this-&amp;gt;configs[$this-&amp;gt;path])) { return $this-&amp;gt;configs[$this-&amp;gt;path][$key]; } elseif ($this-&amp;gt;path == __DIR__) { //如果目录为库目录,则寻找结束,直接返回 return $this-&amp;gt;configs[__DIR__][$key]; } //module目录配置是否加载,否则先加载配置 if (!isset($this-&amp;gt;configs[APP_ROOT])) { $this-&amp;gt;getConfig(APP_ROOT); } //检查module配置是否存在此key if (key_exists($key, $this-&amp;gt;configs[APP_ROOT])) { return $this-&amp;gt;configs[$this-&amp;gt;path][$key]; } //全局配置是否加载,否则先加载配置 if (!isset($this-&amp;gt;configs[__DIR__])) { $this-&amp;gt;getConfig(__DIR__, $key); } return isset($this-&amp;gt;configs[__DIR__][$key]) ? $this-&amp;gt;configs[__DIR__][$key] : &#39;&#39;; } function offsetSet($key, $value) { // $this-&amp;gt;configs[$this-&amp;gt;path][$key] = $value; throw new \\Exception(&quot;cannot write config file.&quot;); } function offsetExists($key) { return isset($this-&amp;gt;configs[$key]); } function offsetUnset($key) { unset($this-&amp;gt;configs[$key]); } } &nbsp; &nbsp;","tags":[]},{"title":"我的php mvc之路系列(一)","date":"2016-03-26T14:37:36.000Z","path":"2016/03/26/e6-88-91-e7-9a-84php-mvc-e4-b9-8b-e8-b7-af-e7-b3-bb-e5-88-97-e4-b8-80/","text":"今天我想分享部分的是 路由调度。 我们采取的url模式是index.php/module/controller/method/param1/value1.html 用的是/做参数分割。先上代码。 $param = Array(); $uri = isset($_SERVER[&#39;PATH_INFO&#39;]) ? $_SERVER[&#39;PATH_INFO&#39;] : &#39;&#39;; //使用path_info模式 if (!isset($_SERVER[&#39;PATH_INFO&#39;]) &amp;amp;&amp;amp; !DEBUG) { throw new \\Exception(&quot;系统不支持path_info&quot;); }`&lt;/pre&gt; &amp;nbsp; 我们首先要关注$_SERVER[&#39;path_info&#39;]这全局变量。你可以把这个把这个变量理解为脚本路径之后的字符串。举一个栗子。 &gt; http://localhost/RandomPHP/Web/Home/Home/index/id/2/name/jack.html 因为我的服务器开启了apache改写规则，我们其实是省略了index.php脚本文件。 $_SERVER[path_info] = &quot;/Home/Home/index/id/2/name/jack.html&quot;; 贴一下apache改写的代码 &lt;pre&gt;&amp;lt;IfModule mod_rewrite.c&amp;gt; Options +FollowSymlinks RewriteEngine On RewriteCond %{REQUEST_FILENAME} !-d RewriteCond %{REQUEST_FILENAME} !-f RewriteRule ^(.*)$ index.php/$1 [QSA] &amp;lt;/IfModule&amp;gt;&lt;/pre&gt; 这里大家可以通过下面这个链接去了解一下apache改写的知识。 **QSA**(query string append) 追加请求字符串 [关于Apache mod_rewrite的中文配置、使用和语法介绍（实现URL重写和防盗链功能）](http://chinablog.blog.51cto.com/276793/280278) 获取到了path_info之后了。我们就要用‘/’这个作为分隔符，把path_info分割成4个数组。 在这之前我们要先把.html伪静态字符先去掉，然后用explode进行字符串分割，注意这里的第三个参数，这个参数控制分割之后的数组个数，然后假如需要分割的元素大于数组个数的话，最后一个数组将会存储剩下的字符串。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`//伪静态处理 if (false !== $pos = strpos($uri, &#39;.&#39;)) { $config = Register::get(&#39;config&#39;); if (substr($uri, $pos + 1) != $config[&#39;suffix&#39;]) { throw new \\Exception(&quot;suffix is not supported&quot;); } else { $uri = substr($uri, 0, $pos); } } //参数分解 $request = explode(&#39;/&#39;, trim($uri, &#39;/&#39;), 4);`&lt;/pre&gt; 然后判断数组的元素个数，如果小于3的话，说明参数没有传够，我们这里统一把它定位到/homr/home/index。作为我们框架的默认页面。 个数大于3的话，那说明还传进了参数。我们需要再次切割这些 参数，把他们解析成key＝value的关联数组和$_GET合并。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`//不规范的url,统一定位到Home/Home/index if (count($request) &amp;lt; 3) { return array(&#39;Home&#39;, &#39;Home&#39;, &#39;index&#39;); } elseif (count($request) &amp;gt; 3) { //get Param preg_replace_callback(&#39;/([^\\/]+)\\/([^\\/]+)/&#39;, function ($match) use (&amp;amp;$param) { $param[strtolower($match[1])] = strip_tags($match[2]); }, array_pop($request)); //把param加入到$_GET $_GET = array_merge($param, $_GET); }`&lt;/pre&gt; 这里的preg_replace_callback($pattern,$function,$string); 第一个是正则表达式，第二个参数函数名或者匿名函数，在函数里面实现replace的操作，第三个参数是要操作的字符串。 array_pop弹出数组的最后一个元素($request[3]＝‘id/2/name/jack’)作为操作的字符串。每一次匹配一组（xx）/（xx）,然后把匹配数组$match传入回调函数。 这个$match的内容是 $match = array( [0]=&amp;gt;&#39;id/2&#39;， //整个字符串 [1]=&amp;gt;&#39;id&#39;， [2]=&amp;gt;&#39;2&#39; ); 然后在回调函数里面我们构造$var[&#39;$match[1]&#39;] = $match[2]; 这样我们就得到了我们要的$var[&#39;id&#39;] = 2; 最后用array_merge讲$var和$_GET进行合并。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`//get Module $router[] = ucwords(array_shift($request)); //get Controller $router[] = ucwords(array_shift($request)); //get Method $router[] = array_shift($request);`&lt;/pre&gt; &amp;nbsp; 最后把$request里面的module和controller都进行首字母大写处理。加入到router数组。返回。 最后贴出完整代码。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php /** * Created by PhpStorm. * User: dengjiaming * Date: 23/3/2016 * Time: 下午3:47 */ namespace Random; class Router { /** * @author DJM &amp;lt;op87960@gmail.com&amp;gt; * @todo url解析 */ static function parseUrl() { // $uri = $_SERVER[&#39;SCRIPT_NAME&#39;]; $param = Array(); $uri = isset($_SERVER[&#39;PATH_INFO&#39;]) ? $_SERVER[&#39;PATH_INFO&#39;] : &#39;&#39;; //使用path_info模式 if (!isset($_SERVER[&#39;PATH_INFO&#39;]) &amp;amp;&amp;amp; !DEBUG) { throw new \\Exception(&quot;系统不支持path_info&quot;); } //伪静态处理 if (false !== $pos = strpos($uri, &#39;.&#39;)) { $config = Register::get(&#39;config&#39;); if (substr($uri, $pos + 1) != $config[&#39;suffix&#39;]) { throw new \\Exception(&quot;suffix is not supported&quot;); } else { $uri = substr($uri, 0, $pos); } } //参数分解 $request = explode(&#39;/&#39;, trim($uri, &#39;/&#39;), 4); //不规范的url,统一定位到Home/Home/index if (count($request) &amp;lt; 3) { return array(&#39;Home&#39;, &#39;Home&#39;, &#39;index&#39;); } elseif (count($request) &amp;gt; 3) { //get Param preg_replace_callback(&#39;/([^\\/]+)\\/([^\\/]+)/&#39;, function ($match) use (&amp;amp;$param) { $param[strtolower($match[1])] = strip_tags($match[2]); }, array_pop($request)); //把param加入到$_GET $_GET = array_merge($param, $_GET); } //get Module $router[] = ucwords(array_shift($request)); //get Controller $router[] = ucwords(array_shift($request)); //get Method $router[] = array_shift($request); return $router; } } &nbsp;","tags":[]},{"title":"Memcached对key和value的限制","date":"2016-03-19T02:28:30.000Z","path":"2016/03/19/memcached-e5-af-b9key-e5-92-8cvalue-e7-9a-84-e9-99-90-e5-88-b6/","text":"Memcached默认的key是255字符。默认的item是(1024*1024)=1m 若要突破限制。则可以通过修改memcached.h里面的源码来实现。 #define KEY_MAX_LENGTH 255 #define MAX_ITEM_SIZE 1024*1024 还可以在启动时增加-I参数。指定max_item_size。","tags":[]},{"title":"MyISAM VS InnoDB","date":"2016-03-17T03:22:32.000Z","path":"2016/03/17/myisam-vs-innodb/","text":"使用MySQL当然会接触到MySQL的存储引擎，在新建数据库和新建数据表的时候都会看到。MySQL默认的存储引擎是MyISAM，其他常用的就是InnoDB了。至于到底用哪种存储引擎比较好？这个问题是没有定论的，需要根据你的需求和环境来衡量。所以对这两种引擎的概念、原理、异同和各自的优劣点有了详细的了解之后，再根据自己的情况选择起来就容易多了。MyISAMInnoDB存储结构每张表被存放在三个文件：1. frm-表格定义2. MYD(MYData)-数据文件3. MYI(MYIndex)-索引文件所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB存储空间MyISAM可被压缩，存储空间较小InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引可移植性、备份及恢复由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了事务安全不支持 每次查询具有原子性支持 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表AUTO_INCREMENTMyISAM表可以和其他字段一起建立联合索引InnoDB中必须包含只有该字段的索引SELECTMyISAM更优INSERTInnoDB更优UPDATEInnoDB更优DELETEInnoDB更优 它不会重新建立表，而是一行一行的删除COUNT without WHEREMyISAM更优。因为MyISAM保存了表的具体行数InnoDB没有保存表的具体行数，需要逐行扫描统计，就很慢了COUNT with WHERE一样一样，InnoDB也会锁表锁只支持表锁支持表锁、行锁 行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的外键不支持支持FULLTEXT全文索引支持不支持 可以通过使用Sphinx从InnoDB中获得全文索引，会慢一点总的来说，MyISAM和InnoDB各有优劣，各有各的使用环境。但是InnoDB的设计目标是处理大容量数据库系统，它的CPU利用率是其它基于磁盘的关系数据库引擎所不能比的。我觉得使用InnoDB可以应对更为复杂的情况，特别是对并发的处理要比MyISAM高效。同时结合memcache也可以缓存SELECT来减少SELECT查询，从而提高整体性能。","tags":[]},{"title":"mysql 不使用索引的情况","date":"2016-03-17T03:21:03.000Z","path":"2016/03/17/mysql-e4-b8-8d-e4-bd-bf-e7-94-a8-e7-b4-a2-e5-bc-95-e7-9a-84-e6-83-85-e5-86-b5/","text":"众所周知，增加索引是提高查询速度的有效途径，但是很多时候，即使增加了索引，查询仍然不使用索引，这种情况严重影响性能，这里就简单总结几条MySQL不使用索引的情况1. 如果MySQL估计使用索引比全表扫描更慢，则不使用索引。例如，如果列key均匀分布在1和100之间，下面的查询使用索引就不是很好：select from table_name where key&gt;1 and key&lt;90;2. 用or分隔开的条件，如果or前的条件中的列有索引，而后面的列没有索引，那么涉及到的索引都不会被用到，例如：select from table_name where key1=’a’ or key2=’b’;如果在key1上有索引而在key2上没有索引，则该查询也不会走索引3. 复合索引，如果索引列不是复合索引的第一部分，则不使用索引（即不符合最左前缀），例如，复合索引为(key1,key2),则查询select from table_name where key2=’b’;将不会使用索引4. 如果like是以‘%’开始的，则该列上的索引不会被使用。例如select from table_name where key1 like ‘%a’；该查询即使key1上存在索引，也不会被使用5. 如果列为字符串，则where条件中必须将字符常量值加引号，否则即使该列上存在索引，也不会被使用。例如,select * from table_name where key1=1;如果key1列保存的是字符串，即使key1上有索引，也不会被使用。从上面可以看出，即使我们建立了索引，也不一定会被使用，那么我们如何知道我们索引的使用情况呢？？在MySQL中，有Handler_read_key和Handler_read_rnd_key两个变量，如果Handler_read_key值很高而Handler_read_rnd_key的值很低，则表明索引经常不被使用，应该重新考虑建立索引。可以通过:show status like ‘Handler_read%’来查看着连个参数的值。","tags":[]},{"title":"cetv（视源） 笔试＋面试","date":"2016-03-16T14:04:08.000Z","path":"2016/03/16/cetv-ef-bc-88-e8-a7-86-e6-ba-90-ef-bc-89-e7-ac-94-e8-af-95-ef-bc-8b-e9-9d-a2-e8-af-95/","text":"首先讲讲笔试。本来是错过了最后一场的在线笔试时间。然后它们竟然发短信过来提示可以再有一次机会。真是煞费苦心啊。 笔试有几个比较深刻。 选择题 排他锁 （悲观锁） ：加了排他锁不能再加共享锁，只允许加了锁的事务进行读写操作。 广义表：这个我还没搞懂。 快排：竟然忘了具体的排序过程。每次选一个曲轴，左右两个指针，右边指针先走，直到遇到比曲轴小的数停下来，左边指针则是遇到比曲轴大的数，然后交换两个指针的值，右边指针继续先走，直到左右指针相遇，算完成一次快排。然后分开区间递归。 面试： 笔试第二天就提醒过了，然后就屁颠屁颠的去了cvte。 Q：先写一个输出从1到1000的素数的程序。 A：我用了5分钟，憋出了一个O（n²）的算法。。 求1-n的素数的算法 1、两层for。内层用i&lt;√n结束。O(n*log(n)) #include &amp;lt;iostream&amp;gt; using namespace std; bool isPrime(int nr) { for (int d = 2; (d * d) &amp;lt; (nr + 1); ++d){ if (!(nr % d)){ return false; } } return true; } int main (int argc, char * const argv[]) { for (int i = 0; i &amp;lt; 50; ++i){ if (isPrime(i)){ cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; endl; } } } `&lt;/pre&gt; 2、排除法_O__(n(log(logn)))_ 一、初始化如下列表。 &lt;pre&gt; 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30&lt;/pre&gt; 二、把第一个数（2）取出来，去掉所有可以被2整除的数。 &lt;pre&gt; 2 3 5 7 9 11 13 15 17 19 21 23 25 27 29&lt;/pre&gt; 三、取第二个数（3），去掉所有可以被 3整除的数。 &lt;pre&gt; 2 3 5 7 11 13 17 19 23 25 29&lt;/pre&gt; 四、取第三个数（5），因为4已经被去除了，再去掉所有可以被5整除的数。 &lt;pre&gt; 2 3 5 7 11 13 17 19 23 29&lt;/pre&gt; 接下来的数是7，但是7的平方是49，其大于了30，所以我们可以停止计算了。剩下的数就是所有的质数了。 3、一个数不能被比它小的素数整除则是素数。复杂度不会算。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`#include &amp;lt;stdio.h&amp;gt; #define NPRIMES 1000 #define FALSE 0 #define TRUE 1 int main(void) { int n; int i,j; int flag; int primes[NPRIMES]; // 保存比 n 小的素数 int level; // 当前素数的数目加1 printf(&quot;Enter value of N &amp;gt; &quot;); scanf(&quot;%d&quot;,&amp;amp;n); level = 0; for(i=2;i&amp;lt;=n;i++) { for(j = 0, flag = TRUE; j&amp;lt;level &amp;amp;&amp;amp; flag; j++) flag = (i%primes[j]); if (flag) { // i 是一个素数 printf(&quot;%12d\\n&quot;, i); if (level &amp;lt; NPRIMES) primes[level++] = i; } } } Q：看你有学过http的编程，请问http报文的header是？ PS：空耳听成http报文结构。然后又扯了一大段。。。 A：Version:版本Header length:头部长度Differentiated services field:QoSTotal length:总长Identification:ip分片（标志符）区分不同进程Flags:标识符（控制是否分片）Fragment offset:分片偏移Time to live (ttl):生存时间，范围0-255。每经过一个理由减1。若TTL=0时。数据被丢弃。通过TTL可以防止数据环路（TTL的重点）。Header checksums:头部校验和Source&amp;Destination:源目IP Header头常用content－type ：application/json、text/plain、text/xml Q：mysql的两个引擎innode与myIsam的区别。（记得一点点。。） Q：mysql用的是btree＋，索引存在哪里。 PS：http://blog.codinglabs.org/articles/theory-of-mysql-index.html &nbsp; &nbsp; &nbsp;","tags":[]},{"title":"4399 php实习生","date":"2016-03-16T13:26:13.000Z","path":"2016/03/16/4399-php-e5-ae-9e-e4-b9-a0-e7-94-9f/","text":"网申之后，面试安排在华工的B7－4楼。 坐下之后做了一个简单的自我介绍：“我是来自广工的一名大三的实习生，平时喜欢逛国内各种技术论坛和研究开源技术，今天过来打算找一个好的实习。” 然后面试官问到了以下的问题。 Q：http的报文是怎么传播的（并不是问报文结构）。假如从浏览器输入一个网址开始。 PS：我猜他应该想问的是用了什么协议之类。 A：首先输入网址之后就通过DNS协议进行解析，然后，（我想了想中间好像就没有什么协议了）通过http协议和服务器端建立tcp连接，三次握手，然后发http包，http1.1可以保持长连接，建立一次连接，可以不断发送http数据包。 Q：SMARTY引擎有没有使用过，模版引擎的好处是？ A：没有用过SMARTY，模版引擎的作用是可以模版继承？？（想想都觉得自己没答到点了。然后跟面试官吹了一大段例子）。 PS：这边的正答应该是（直接截取SMARTY官网的描述） 1、干净地分离显示逻辑和程序代码2、PHP后端，Smarty模板前端 3、增强PHP, 而不是取代它 4、程序员和设计师的快速开发/部署 5、快速和简单的维护 6、语法简单易懂，无须懂PHP 7、灵活的自定义开发 8、安全: 隔离于PHPQ：session存放在哪里？ A：一般在文件，还可以在php.ini指定其它存放的方式。例如数据库或者memcached（坑了自己，鉴于memcached用的是LRU算法来对每一个slab来回收，就是说大小相近的在同一个slab的数据会被回收，用户会莫名其妙的掉线）。 Q：单例模式是什么？有什么好处？ A：设置一个全局的静态类。例如数据库类。在程序运行过程中保持单一的一个数据库类。好处是节约系统资源。 最后面试官问我还有什么问题要问他。 我问 Q：为什么这次就招php的实习生？（弱智的问题） A：处于公司的战略。（敷衍） Q：4399在广州吗？（废话！！） A：是的 Q：4399现在用的是什么框架？ A：用的是公司自己开发的框架，和SMARTY引擎。 9号面的，现在都没有答复。GG。","tags":[]},{"title":"PSR7 HTTP消息接口","date":"2016-03-13T07:18:00.000Z","path":"2016/03/13/psr7-http-e6-b6-88-e6-81-af-e6-8e-a5-e5-8f-a3/","text":"留空。。。","tags":[]},{"title":"PSR6 缓存接口","date":"2016-03-13T03:59:25.000Z","path":"2016/03/13/psr6-e7-bc-93-e5-ad-98-e6-8e-a5-e5-8f-a3/","text":"还是先留空，等以后有深刻了解了再回来写。","tags":[]},{"title":"PSR4 自动加载(autoload)增强版","date":"2016-03-13T03:58:28.000Z","path":"2016/03/13/psr4-e8-87-aa-e5-8a-a8-e5-8a-a0-e8-bd-bdautoload-e5-a2-9e-e5-bc-ba-e7-89-88/","text":"PSR4是对PSR0的补充，基本可以替代PSR0了。 我简单说下，主要是以下几点：1. 废除了PSR-0中_就是目录分割符的写法，_下划线在完全限定类名中是没有特殊含义了。2. 类文件名要以 .php 结尾。3. 类名必须要和对应的文件名要一模一样，大小写也要一模一样。 给出一些link大家去参详一下。我也不是太懂。哈哈 http://segmentfault.com/a/1190000000380008http://www.4wei.cn/archives/1002186http://wenku.baidu.com/view/7a21e44b48d7c1c708a14577.html#10002-tsina-1-87843-e29b4784eda5d1f51fb0c2a97a15da08https://github.com/hfcorriez/fig-standards 最后贴出官方的例子。 Closure Example&amp;lt;?php /** * An example of a project-specific implementation. * * After registering this autoload function with SPL, the following line * would cause the function to attempt to load the \\Foo\\Bar\\Baz\\Qux class * from /path/to/project/src/Baz/Qux.php: * * new \\Foo\\Bar\\Baz\\Qux; * * @param string $class The fully-qualified class name. * @return void */ spl_autoload_register(function ($class) { // project-specific namespace prefix $prefix = &#39;Foo\\\\Bar\\\\&#39;; // base directory for the namespace prefix $base_dir = __DIR__ . &#39;/src/&#39;; // does the class use the namespace prefix? $len = strlen($prefix); if (strncmp($prefix, $class, $len) !== 0) { // no, move to the next registered autoloader return; } // get the relative class name $relative_class = substr($class, $len); // replace the namespace prefix with the base directory, replace namespace // separators with directory separators in the relative class name, append // with .php $file = $base_dir . str_replace(&#39;\\\\&#39;, &#39;/&#39;, $relative_class) . &#39;.php&#39;; // if the file exists, require it if (file_exists($file)) { require $file; } });`&lt;/pre&gt; &amp;nbsp; ## Class Example &amp;nbsp; &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php namespace Example; /** * An example of a general-purpose implementation that includes the optional * functionality of allowing multiple base directories for a single namespace * prefix. * * Given a foo-bar package of classes in the file system at the following * paths ... * * /path/to/packages/foo-bar/ * src/ * Baz.php # Foo\\Bar\\Baz * Qux/ * Quux.php # Foo\\Bar\\Qux\\Quux * tests/ * BazTest.php # Foo\\Bar\\BazTest * Qux/ * QuuxTest.php # Foo\\Bar\\Qux\\QuuxTest * * ... add the path to the class files for the \\Foo\\Bar\\ namespace prefix * as follows: * * &amp;lt;?php * // instantiate the loader * $loader = new \\Example\\Psr4AutoloaderClass; * * // register the autoloader * $loader-&amp;gt;register(); * * // register the base directories for the namespace prefix * $loader-&amp;gt;addNamespace(&#39;Foo\\Bar&#39;, &#39;/path/to/packages/foo-bar/src&#39;); * $loader-&amp;gt;addNamespace(&#39;Foo\\Bar&#39;, &#39;/path/to/packages/foo-bar/tests&#39;); * * The following line would cause the autoloader to attempt to load the * \\Foo\\Bar\\Qux\\Quux class from /path/to/packages/foo-bar/src/Qux/Quux.php: * * &amp;lt;?php * new \\Foo\\Bar\\Qux\\Quux; * * The following line would cause the autoloader to attempt to load the * \\Foo\\Bar\\Qux\\QuuxTest class from /path/to/packages/foo-bar/tests/Qux/QuuxTest.php: * * &amp;lt;?php * new \\Foo\\Bar\\Qux\\QuuxTest; */ class Psr4AutoloaderClass { /** * An associative array where the key is a namespace prefix and the value * is an array of base directories for classes in that namespace. * * @var array */ protected $prefixes = array(); /** * Register loader with SPL autoloader stack. * * @return void */ public function register() { spl_autoload_register(array($this, &#39;loadClass&#39;)); } /** * Adds a base directory for a namespace prefix. * * @param string $prefix The namespace prefix. * @param string $base_dir A base directory for class files in the * namespace. * @param bool $prepend If true, prepend the base directory to the stack * instead of appending it; this causes it to be searched first rather * than last. * @return void */ public function addNamespace($prefix, $base_dir, $prepend = false) { // normalize namespace prefix $prefix = trim($prefix, &#39;\\\\&#39;) . &#39;\\\\&#39;; // normalize the base directory with a trailing separator $base_dir = rtrim($base_dir, DIRECTORY_SEPARATOR) . &#39;/&#39;; // initialize the namespace prefix array if (isset($this-&amp;gt;prefixes[$prefix]) === false) { $this-&amp;gt;prefixes[$prefix] = array(); } // retain the base directory for the namespace prefix if ($prepend) { array_unshift($this-&amp;gt;prefixes[$prefix], $base_dir); } else { array_push($this-&amp;gt;prefixes[$prefix], $base_dir); } } /** * Loads the class file for a given class name. * * @param string $class The fully-qualified class name. * @return mixed The mapped file name on success, or boolean false on * failure. */ public function loadClass($class) { // the current namespace prefix $prefix = $class; // work backwards through the namespace names of the fully-qualified // class name to find a mapped file name while (false !== $pos = strrpos($prefix, &#39;\\\\&#39;)) { // retain the trailing namespace separator in the prefix $prefix = substr($class, 0, $pos + 1); // the rest is the relative class name $relative_class = substr($class, $pos + 1); // try to load a mapped file for the prefix and relative class $mapped_file = $this-&amp;gt;loadMappedFile($prefix, $relative_class); if ($mapped_file) { return $mapped_file; } // remove the trailing namespace separator for the next iteration // of strrpos() $prefix = rtrim($prefix, &#39;\\\\&#39;); } // never found a mapped file return false; } /** * Load the mapped file for a namespace prefix and relative class. * * @param string $prefix The namespace prefix. * @param string $relative_class The relative class name. * @return mixed Boolean false if no mapped file can be loaded, or the * name of the mapped file that was loaded. */ protected function loadMappedFile($prefix, $relative_class) { // are there any base directories for this namespace prefix? if (isset($this-&amp;gt;prefixes[$prefix]) === false) { return false; } // look through base directories for this namespace prefix foreach ($this-&amp;gt;prefixes[$prefix] as $base_dir) { // replace the namespace prefix with the base directory, // replace namespace separators with directory separators // in the relative class name, append with .php $file = $base_dir . str_replace(&#39;\\\\&#39;, &#39;/&#39;, $relative_class) . &#39;.php&#39;; // if the mapped file exists, require it if ($this-&amp;gt;requireFile($file)) { // yes, we&#39;re done return $file; } } // never found it return false; } /** * If a file exists, require it from the file system. * * @param string $file The file to require. * @return bool True if the file exists, false if not. */ protected function requireFile($file) { if (file_exists($file)) { require $file; return true; } return false; } }`&lt;/pre&gt; &amp;nbsp; ### Unit Tests &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php namespace Example\\Tests; class MockPsr4AutoloaderClass extends Psr4AutoloaderClass { protected $files = array(); public function setFiles(array $files) { $this-&amp;gt;files = $files; } protected function requireFile($file) { return in_array($file, $this-&amp;gt;files); } } class Psr4AutoloaderClassTest extends \\PHPUnit_Framework_TestCase { protected $loader; protected function setUp() { $this-&amp;gt;loader = new MockPsr4AutoloaderClass; $this-&amp;gt;loader-&amp;gt;setFiles(array( &#39;/vendor/foo.bar/src/ClassName.php&#39;, &#39;/vendor/foo.bar/src/DoomClassName.php&#39;, &#39;/vendor/foo.bar/tests/ClassNameTest.php&#39;, &#39;/vendor/foo.bardoom/src/ClassName.php&#39;, &#39;/vendor/foo.bar.baz.dib/src/ClassName.php&#39;, &#39;/vendor/foo.bar.baz.dib.zim.gir/src/ClassName.php&#39;, )); $this-&amp;gt;loader-&amp;gt;addNamespace( &#39;Foo\\Bar&#39;, &#39;/vendor/foo.bar/src&#39; ); $this-&amp;gt;loader-&amp;gt;addNamespace( &#39;Foo\\Bar&#39;, &#39;/vendor/foo.bar/tests&#39; ); $this-&amp;gt;loader-&amp;gt;addNamespace( &#39;Foo\\BarDoom&#39;, &#39;/vendor/foo.bardoom/src&#39; ); $this-&amp;gt;loader-&amp;gt;addNamespace( &#39;Foo\\Bar\\Baz\\Dib&#39;, &#39;/vendor/foo.bar.baz.dib/src&#39; ); $this-&amp;gt;loader-&amp;gt;addNamespace( &#39;Foo\\Bar\\Baz\\Dib\\Zim\\Gir&#39;, &#39;/vendor/foo.bar.baz.dib.zim.gir/src&#39; ); } public function testExistingFile() { $actual = $this-&amp;gt;loader-&amp;gt;loadClass(&#39;Foo\\Bar\\ClassName&#39;); $expect = &#39;/vendor/foo.bar/src/ClassName.php&#39;; $this-&amp;gt;assertSame($expect, $actual); $actual = $this-&amp;gt;loader-&amp;gt;loadClass(&#39;Foo\\Bar\\ClassNameTest&#39;); $expect = &#39;/vendor/foo.bar/tests/ClassNameTest.php&#39;; $this-&amp;gt;assertSame($expect, $actual); } public function testMissingFile() { $actual = $this-&amp;gt;loader-&amp;gt;loadClass(&#39;No_Vendor\\No_Package\\NoClass&#39;); $this-&amp;gt;assertFalse($actual); } public function testDeepFile() { $actual = $this-&amp;gt;loader-&amp;gt;loadClass(&#39;Foo\\Bar\\Baz\\Dib\\Zim\\Gir\\ClassName&#39;); $expect = &#39;/vendor/foo.bar.baz.dib.zim.gir/src/ClassName.php&#39;; $this-&amp;gt;assertSame($expect, $actual); } public function testConfusion() { $actual = $this-&amp;gt;loader-&amp;gt;loadClass(&#39;Foo\\Bar\\DoomClassName&#39;); $expect = &#39;/vendor/foo.bar/src/DoomClassName.php&#39;; $this-&amp;gt;assertSame($expect, $actual); $actual = $this-&amp;gt;loader-&amp;gt;loadClass(&#39;Foo\\BarDoom\\ClassName&#39;); $expect = &#39;/vendor/foo.bardoom/src/ClassName.php&#39;; $this-&amp;gt;assertSame($expect, $actual); } } &nbsp;","tags":[]},{"title":"PSR3 日志接口","date":"2016-03-13T03:30:15.000Z","path":"2016/03/13/psr3-e6-97-a5-e5-bf-97-e6-8e-a5-e5-8f-a3/","text":"这一规范主要是实现日志接口的一个规范，因为暂时没用到，所以先不介绍，以后补上。","tags":[]},{"title":"PSR2 代码风格指导","date":"2016-03-13T03:27:30.000Z","path":"2016/03/13/psr2/","text":"PSR2 编码风格向导。 PSR2是用来约束代码风格的。可是说是所有里面最关键最重要的，也是需要好好规范和共同遵守的。 还是按照惯例一句句的翻译。 1、Code MUST follow a “coding style guide” PSR [PSR-1]. 代码必须遵循psr1规范。 2、Code MUST use 4 spaces for indenting, not tabs. 代码必须使用4个空格来缩进，而不是tab键这一点感触较深，因为用sublime或者phpstrom的时候，默认tab是4个空格，可是到了win下面的notepad++，就变成2个空格了，瞬间代码就变得不堪入目。。3、There MUST NOT be a hard limit on line length; the soft limit MUST be 120 characters; lines SHOULD be 80 characters or less. 代码行的长度不应该硬性规定，一个行长度要求必须小于120个字符，应该小于80字符或更少。 4、There MUST be one blank line after the namespace declaration, and there MUST be one blank line after the block of use declarations. 在namespace的声明下面必须要有一空行，在声明use下面也必须有一空行。 &amp;lt;?php namespace \\Project\\First\\Learn; use \\Project\\First\\Learn\\AClass; class MyClass ( ) { }`&lt;/pre&gt; &gt; 5、Opening braces for classes MUST go on the next line, and closing braces MUST go on the next line after the body. 6、Opening braces for methods MUST go on the next line, and closing braces MUST go on the next line after the body. _**类和方法**_开始的大括号必须另起一行，结束的大括号也必须在最后另起一行。 7、Visibility MUST be declared on all properties and methods; `abstract` and `final` MUST be declared before the visibility; `static` MUST be declared after the visibility. 所有**属性和方法**前面必须声明其**可见性，**abstract 和final必须修饰在可见性之前，static必须声明在可见性之后。 什么是visibility可见性呢，其实就是三个访问控制符public、protected、private.这里要注意不能省略不写，也不可以用var来定义php的变量（var是php4里面使用，php5里面var等同于public） 8、Control structure keywords MUST have one space after them; method and function calls MUST NOT. 控制结构的关键词的后面必须要一个空格，方法和函数调用则不能够有空格。 9、Opening braces for control structures MUST go on the same line, and closing braces MUST go on the next line after the body. 控制结构的开始大括号必须不换行，结束大括号必须换行。 10、Opening parentheses for control structures MUST NOT have a space after them, and closing parentheses for control structures MUST NOT have a space before. 控制结构的开始圆括号之后不能有空格，结束圆括号之前也不能够出现空格。 上面的8－10点我最后会贴出一个例子来说明。 下面补充几点。 &gt; 1、源文件 All PHP files MUST use the Unix LF (linefeed) line ending. All PHP files MUST end with a single blank line. The closing `?&amp;gt;` tag MUST be omitted from files containing only PHP. 所有的php源文件必须是用LF做换行符，结尾必须要留一空行且不能够有?&amp;gt; 不能够以?&amp;gt;结尾是因为防止在结尾之后出现空行或者其它误输入导致脚本不正常输出。 2、行 Blank lines MAY be added to improve readability and to indicate related blocks of code. There MUST NOT be more than one statement per line. 可以加入适当的空行来增强代码的可阅读性和指出相关的代码块。 每行必须只有一句php代码。 3、关键字和Ture、False、Null PHP [keywords](http://php.net/manual/en/reserved.keywords.php) MUST be in lower case. The PHP constants `true`, `false`, and `null` MUST be in lower case. php的关键字和true、false、null必须小写 4、继承与实现 The `extends` and `implements` keywords MUST be declared on the same line as the class name. 继承和实现这两个关键字必须与类名在同一行声明。 Lists of `implements` MAY be split across multiple lines, where each subsequent line is indented once. When doing so, the first item in the list MUST be on the next line, and there MUST be only one interface per line. um，好长，，直接举例子。 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`class ClassName extends ParentClass implements \\ArrayAccess, \\Countable, \\Serializable { // constants, properties, methods }`&lt;/pre&gt; 最后给一个官方的完全遵循了psr2的代码。要注意if的空格，他和foreach、switch case、for、while、do while、try catch的空格要求是一样的： 1、关键词后面要空，if () 2、第一个参数和最后一个参数贴紧圆括号.参数后逗号然后空格之后才是下一个参数。 if ($a, $b, $c) 3、开始花括号不能换行，结束大括号必须换行。 if ($a, $b, $c) { } 4.switch的break;要换行写。 switch ($str) { case 0: echo &#39;0&#39;; break; } &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php namespace Vendor\\Package; use FooInterface; use BarClass as Bar; use OtherVendor\\OtherPackage\\BazClass; class Foo extends Bar implements FooInterface { public function sampleFunction($a, $b = null) { if ($a === $b) { bar(); } elseif ($a &amp;gt; $b) { $foo-&amp;gt;bar($arg1); } else { BazClass::bar($arg2, $arg3); } } final public static function bar() { // method body } } &nbsp; &nbsp;","tags":[]},{"title":"PSR1 基本代码规范","date":"2016-03-12T14:35:08.000Z","path":"2016/03/12/psr1/","text":"psr1讲的是基本代码规范。下面我们来看一下。 1、Files MUST use only &amp;lt;?php and &amp;lt;?= tags. php文件必须只能使用&lt;?php和&lt;?=标签嗯。好。第二条2、Files MUST use only UTF-8 without BOM for PHP code. php文件必须使用没有bom头的utf－8编码。这个很重要，很多人发现自己的php会发生一些莫名其妙的错误，很多时候就是编码的问题。可以利用notepad++来改变编码。3、Files SHOULD either declare symbols (classes, functions, constants, etc.) _or _cause side-effects (e.g. generate output, change .ini settings, etc.) but SHOULD NOT do both. php文件应该（建议）用来声明类，方法，常量等等。或者用来做一些会造成附加影响的操作。例如输出，更改配置等等。但是它们不应该（建议）同时存在同一个文件当中这里的意思就是在一文件里面不要同时出现(function,class,const)和(echo,ini_set)。4、Namespaces and classes MUST follow an “autoloading” PSR: [PSR-0, PSR-4]. 命名规则必须遵循自动载入psr0或psr4.继续。。5、Class names MUST be declared in StudlyCaps. 类名必须用大驼峰声明class MyClass{}6、Class constants MUST be declared in all upper case with underscore separators. 类常量声明必须用大写和下划线隔开const MY_VALUE;7、Method names MUST be declared in camelCase. 方法名必须以小驼峰命名。public function getName(){} 完。","tags":[]},{"title":"PSR0 自动加载标准（Autoloading Standard）","date":"2016-03-12T14:15:26.000Z","path":"2016/03/12/psr0/","text":"由于psr4的出现，psr0是官方不推荐使用的，可是学多了总没坏，接下来让我们了解一下这套标准。 他主要有6点。 1、命名空间一定要与绝对路径一致。\\Vendor\\namespace\\例如你有一个文件是 Path/Doctrine/Common/IsolatedClassLoader.php namespace \\Doctrine\\Common\\ $IsolatedClassLoader = new \\Doctrine\\Common\\IsolatedClassLoader; 上面的例子很明显，当new一个 \\Doctrine\\Common\\IsolatedClassLoader的时候，系统按照这个顺序去查找Vendor -&gt; Doctrine -&gt; Common -&gt; IsolatedClassLoader.php 2、当从文件系统中载入时，合格的namespace和class一定是以 .php 结尾的这个。。嗯嗯，相信没人会用php1、php2这样的后缀吧。。3、当从文件系统中加载时，每个namespace的分隔符(/)要转换成 DIRECTORY_SEPARATOR(操作系统路径分隔符) \\Zend\\Mail\\Message =&gt; /path/to/project/lib/vendor/Zend/Mail/Message.php 4、在类名中，每个下划线(_)符号要转换成DIRECTORY_SEPARATOR(操作系统路径分隔符)。在namespace中，下划线(_)符号是没有（特殊）意义的。 \\namespace\\package_name\\Class_Name =&gt;/path/to/project/lib/vendor/namespace/package_name/Class/Name.php注意看package_name和Class_Name转化为路径的区别。 5、verdor name,namespaces,class名可以由大小写字母组合而成（大小写敏感的）这个大小写问题要重视，因为在liunx下面目录和文件都是区分大小写的。6、只能有一个入口文件，其它的每一个php文件都必须只有一个类。","tags":[]},{"title":"PSR系列 Proposing a Standards Recommendation（提出标准建议）","date":"2016-03-12T12:32:19.000Z","path":"2016/03/12/psr-e7-b3-bb-e5-88-97/","text":"在说啥是PSR-[0-7]规范的之前，我觉得我们有必要说下它的发明者和规范者：PHP-FIG，它的网站是：www.php-fig.org。就是这个联盟组织发明和创造了PSR-[0-7]规范，膜拜吧，屌丝们！ FIG 是 Framework Interoperability Group（框架可互用性小组）的缩写，由几位开源框架的开发者成立于 2009 年，从那开始也选取了很多其他成员进来，虽然不是 “官方” 组织，但也代表了社区中不小的一块。组织的目的在于：以最低程度的限制，来统一各个项目的编码规范，避免各家自行发展的风格阻碍了程序设计师开发的困扰，于是大伙发明和总结了PSR，PSR是Proposing a Standards Recommendation（提出标准建议）的缩写，截止到目前为止，总共有7套PSR规范，分别是： PSR-0 (Autoloading Standard) 自动加载标准 PSR-1 (Basic Coding Standard) 基础编码标准 PSR-2 (Coding Style Guide) 编码风格向导 PSR-3 (Logger Interface) 日志接口 PSR-4 (Improved Autoloading) 自动加载的增强版，可以替换掉PSR-0了。 PSR-6(Caching Interface)缓存接口 PSR-7(HTTP Message Interface)http消息接口 接下来的篇目，我们会针对这7套，深入了解下。仔细学习下受万千PHPer热捧的这7套规范到底有啥出众之处。","tags":[]},{"title":"提高php性能的N种方法（二、Memcached）","date":"2016-03-07T11:56:57.000Z","path":"2016/03/07/e6-8f-90-e9-ab-98php-e6-80-a7-e8-83-bd-e7-9a-84n-e7-a7-8d-e6-96-b9-e6-b3-95-ef-bc-88-e4-ba-8c-e3-80-81memcached-ef-bc-89/","text":"惯例摘录百度百科对Memcached的描述。 Memcached 是一个高性能的分布式内存对象缓存系统，用于动态Web应用以减轻数据库负载。它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的速度。Memcached基于一个存储键/值对的hashmap。其守护进程（daemon ）是用C写的，但是客户端可以用任何语言来编写，并通过memcached协议与守护进程通信。Memcached是基于键值对的hashmap，贮存于内存，只支持储存字符串类型，垃圾回收采用LRU（最近未使用算法），对小型静态数据进行缓存处理，尤其是html代码段，在处理元数据时所消耗的内存资源相对Redis（另外一个负盛名的键值数据存储方案。下次会讲到）更少。 介绍完之后，说说他的安装和配置。 分客户端和服务器端 1、客户端（开启Memcached的php扩展） 1）如果你的php包是使用yum（Redhat/Fedora/Centos）一键安装的。可以采用 yum install php-pecl-memcache进行安装（不建议）。 2）pecl安装。这是第二简洁的方案。只要你熟悉使用pecl安装php的扩展的话。 pecl install memcache yum install zlib-devel echo ‘extension=memcache.so’ &gt;&gt; /etc/php.ini 3）从官网下载编译安装。以上两种方法均失败的话。就只能使用这个方法了，如下：wget http://pecl.[php.net/get/memcache-2.2.7.tgz](http://php.net/get/memcache-2.2.7.tgz) tar -zxvf memcache-2.2.7.tgzc cd memcache-2.2.7 /usr/local/php/bin/phpize ./configure –with-php-config=/usr/local/php/bin/php-config make &amp;&amp; make install 注意：/usr/local/php/ 为php的安装路径，需要根据你安装的实际目录调整。 安装成功后会显示你的memcache.so扩展的位置，比如我的： Installing shared extensions:/usr/local/php/lib/php/extensions/no-debug-non-zts-20090626/最后我们需要把这个扩展添加到php中，打开你的php.ini文件在最后添加以下内容：&gt; &gt;&gt; &gt;&gt; [Memcache]&gt;&gt; extension_dir = “/usr/local/php/lib/php/extensions/no-debug-non-zts-20090626/“&gt;&gt; extension = memcache.so&gt;&gt; &gt;&gt; &gt;&gt; 最后重启服务器（Apache）&gt; /usr/local/apache2/bin/httpd －k restart检查安装结果/usr/local/php/bin/php -m | grep memcache安装成功会输出：memcache。2、安装服务器端 1）Linux系统安装memcached，首先要先安装lib event库。&gt; &gt;&gt;&gt; sudo apt-get install libevent libevent-devel 自动下载安装（Ubuntu/Debian）&gt;&gt; yum install libevent libevent-devel 自动下载安装（Redhat/Fedora/Centos）&gt;&gt; 2）安装MemcachedUbuntu/Debiansudo apt-get install memcachedRedhat/Fedora/Centosyum install memcached3）启动选项： -d是启动一个守护进程； -m是分配给Memcache使用的内存数量，单位是MB； -u是运行Memcache的用户； -l是监听的服务器IP地址，可以有多个地址； -p是设置Memcache监听的端口，，最好是1024以上的端口； -c是最大运行的并发连接数，默认是1024；* -P是设置保存Memcache的pid文件。&gt; /usr/local/memcached/bin/memcached -p 11211 -m 64m -d -u root","tags":[]},{"title":"提高php性能的N种方法（一、Xcache）","date":"2016-03-07T11:31:31.000Z","path":"2016/03/07/e6-8f-90-e4-be-9bphp-e6-80-a7-e8-83-bd-e7-9a-84n-e7-a7-8d-e6-96-b9-e6-b3-95-ef-bc-88-e4-b8-80-e3-80-81xcache-ef-bc-89/","text":"首先摘录一段在百度百科对Xcache的介绍： XCache 是一个开源的 opcode 缓存器/优化器, 这意味着他能够提高您服务器上的 PHP 性能. 他通过把编译 PHP 后的数据缓冲到共享内存从而避免重复的编译过程, 能够直接使用缓冲区已编译的代码从而提高速度. 通常能够提高您的页面生成速率 2 到5 倍, 降低服务器负载.没错。配置Xcache会把你的php编译后的opcode做缓存。他还提供了变量缓存功能（存放在内存），下面会介绍Xcache的安装和配置。 wget -c http://xcache.lighttpd.net/pub/Releases/3.2.0/xcache-3.2.0.tar.gztar zxvf xcache-3.2.0.tar.gzcd xcache-3.2.0/usr/local/php/bin/phpize # ./configure –enable-xcache –enable-xcache-coverager –enable-xcache-optimizer –with-php-config=/usr/bin/php-config# make &amp;&amp; make install以上为安装过程，注：–enable-xcache 表示启用Xcache支持；–enable-xcache-coverager 表示包含用于测量加速器功效的附加特性；–enable-xcache-optimizer表示启用操作码优化echo “extension=xxxx” &gt;&gt; /etc/php.ini (在php.ini里面开启Xcache扩展)cat cache.ini &gt;&gt; php.ini (复制Xcache自带的默认配置copy一份到php.ini)cp -r /htdocs /var/www/html/(把Xcache的管理页面移动你的web目录)检验Xcache是否安装成功 php -v 。下面这段配置开启Xcache管理页面的http认证（一般建议开启）[xcache.admin] xcache.admin.enable_auth = On //开启后就能使用Xcache的admin页面了 xcache.admin.user = “admin”;/run: echo -n “yourpassword” |md5sum |awk ‘{print }’ to get md5 password/ xcache.admin.pass = “安装时候输入的密码（MD5密文）”下面这段是Xcache的常规配置[xcache]xcache.cacher = On // 使用/不使用 opcode 缓存器. xcache.size = 0 时无效.xcache.shm_scheme = “mmap”xcache.size = 20M //0 禁止, 非 0 则启用缓存器. 请注意您系统所允许的 mmap 最大值.; set to cpu count (cat /proc/cpuinfo |grep -c processor)xcache.count = 4 //建议和cpu核数一样xcache.slots = 8K //只是作为 hash 槽个数的参考值, 您可以放心地缓冲超过这个个数的项目.xcache.ttl = 0 //设置缓冲项目的 Ttl (Time To Live) 值, 0=永不过期.xcache.gc_interval = 0 //检查过期项目, 回收内存空间的间隔.xcache.var_size = 4Mxcache.var_count = 1xcache.var_slots = 8Kxcache.var_ttl = 0xcache.var_maxttl = 0xcache.var_gc_interval = 300xcache.readonly_protection = Off; for nix, xcache.mmap_path is a file path, not directory. (auto create/overwrite); Use something like “/tmp/xcache” instead of “/dev/“ if you want to turn on ReadonlyProtection ; different process group of php won’t share the same /tmp/xcachexcache.mmap_path = “/dev/zero”xcache.coredump_directory = “”xcache.experimental = Offxcache.stat = Onxcache.optimizer = Off最重要的参数是xcache.var_size和xcache.size，可以根据内存设置，但是在top中，内存占用直接多出来很多，比如都设置了为256M，则php-cgi的占用就在530M左右，基本的php大约10-15M，加上512M，就快到530了。","tags":[]},{"title":"http状态码（常用）","date":"2016-03-06T08:12:59.000Z","path":"2016/03/06/http-e7-8a-b6-e6-80-81-e7-a0-81-ef-bc-88-e5-b8-b8-e7-94-a8-ef-bc-89/","text":"1XX 消息类型101 Switching Protocols 在websocket通信用到2XX成功200 ok 表示成功，请求所希望的响应头或数据体将随此响应返回。206 Partial Content 部分内容，只能用get，迅雷等下载工具断点续传。或者在线视频3XX重定向301 Moved Permanently 资源永久转移，新的location会被缓存302 Found 资源临时转移，除非有制定缓存头，否则下次会继续向原有地址发送。如果这不是一个GET或者HEAD请求，因此浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。注意：对于某些使用HTTP/1.0协议的浏览器，当它们发送的POST请求得到了一个301响应的话，接下来的重定向请求将会变成GET方式304 Not Modify 客户端的缓存资源是最新的。（要用户使用缓存）4XX 客户端错误400 Bad Request 由于包含语法错误，当前请求无法被服务器理解。401 UnAuthorized 要求用户验证。该响应必须包含一个适用于被请求资源的WWW-Authenticate信息头用以询问用户信息。403 Forbidden 禁止访问404 Not Found 请求失败，请求所希望得到的资源未被在服务器上发现。405 Method Not Allowed 服务器不支持使用的方法5XX服务器错误500 internal Server Error 服务器内部错误（程序语法错误）501 Not Implemented 未实现的方法502 Bad Gateway 无效的网关或代理503 Services Unavailable 服务器过载504 Gateway Timeout 网关超时","tags":[]},{"title":"（转）PHP新的垃圾回收机制:Zend GC详解","date":"2016-03-03T13:29:13.000Z","path":"2016/03/03/wp-syntax-e4-bb-a3-e7-a0-81-e9-ab-98-e4-ba-ae-e6-8f-92-e4-bb-b6-e6-b5-8b-e8-af-95/","text":"先介绍php的变量机制。 在引擎内部，变量都是用一个结构体来表示，这个结构体可以在{PHPSRC}/Zend/zend.h中找到： struct _zval_struct { /* Variable information */ zvalue_value value; /* value */ zend_uint refcount__gc; zend_uchar type; /* active type */ zend_uchar is_ref__gc; }; `&lt;/pre&gt; value是变量具体的值。type是变量在运行时的类型（动态的）。 value的类型zvalue_value同样定义在此文件中： &lt;pre class=&quot;pure-highlightjs&quot;&gt;`typedef union _zvalue_value { long lval; /* long value */ double dval; /* double value */ struct { char *val; int len; } str; HashTable *ht; /* hash table value */ zend_object_value obj; } zvalue_value;`&lt;/pre&gt; &amp;nbsp; 根据要转化的类型。在{PHPSRC}/Zend/zend_operators.c中定义了各种类型转换的宏，比如转换成布尔类型的宏zendi_convert_to_boolean，主要的思路就是先把type变成IS_BOOL,然后根据原变量的不同类型的值按照一定规则转换成lval的0或则1。 refcount引用计数，is_ref是否引用变量 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php //值引用 $strA = &#39;a string&#39;; /*$strA {refcount=1,is_ref=0}*/ $strB = $strA; /*$strA 、$strB{refcount=2,is_ref=0}*/ $strB = &#39;also a string&#39;; /*$strA{refcount=1,is_ref=0} $strB{refcount=1,is_ref=0}*/ ?&amp;gt;`&lt;/pre&gt; 值引用的两个变量都是指向同一个zval。当$strB被赋值时，会发生变量复制（copy on write） &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php //指针引用 $strA = &#39;a string&#39;; /*$strA {refcount=1,is_ref=0}*/ $strB = &amp;amp;$strA; /*$strA 、$strB{refcount=2,is_ref=1}*/ $strB = &#39;also a string&#39;; /*$strA 、$strB{refcount=2,is_ref=1}*/ ?&amp;gt;`&lt;/pre&gt; 上面的例子，指针引用的时候不会发生变量分离，两个变量还是指向同一个zval，echo $strA为新修改的值。 unset unset不是一个函数，而是一个语言结构，主要是从当前符号表中删除参数中的符号，先执行析构函数把这个变量指向的zval.refcount--，当refcount==0时，这个zval才会被释放。 php5.3新增了gc机制。看了原博客的对源码的分析，感觉不太理解。所以直接贴出我对它过程的一个理解。 1、首先垃圾的判断：refcount被减少后，仍不等于0，此时zval有可能是垃圾。 2、举一个会产生垃圾的例子 &lt;pre class=&quot;pure-highlightjs&quot;&gt;`&amp;lt;?php $a = array(&quot;one&quot;); $a[] = &amp;amp;$a; unset($a); ?&amp;gt; 因为在php里面数组都是hash表。引用一张图片 unset($a)后。 此时符号表中已经不存在$a这个符号了。可是数组已经不能引用了。此时这个array便是垃圾。 3、gc过程 gc_mark_roots() 这个函数对节点信息的链表进行一次深度优先遍历，将其中的zval的refcount减1，为了避免对同一个zval重复减操作，在操作之后将zval标记成灰色。（对节点自身的zval可以重复减操作，这个是此算法的基础） gc_scan_roots() 这个函数对节点信息的链表再次进行深度优先遍历，如果发现zval的refcount大于等于1，则对该zval和其包含的zval的refcount加1操作，这个是对非垃圾的一个信息还原，然后将这些zval颜色属性去掉(设置成black)。如果发现zval的refcount等于0，则就标记成白色，这些是后面将要清理掉的垃圾。 gc_collect_roots() 遍历节点信息链表,将前面一个步骤中标记为白色的节点信息放到GC_G(zval_to_free)为入口的链表中，这个链表用来存放将要释放的垃圾。 然后释放掉全部的节点信息，缓冲区被清空。分析结束后将重新收集节点信息。 最后释放链表存在的垃圾 看到最后，大家可以根据这个算法去分析一下上面的两种情况，gc是否会工作，怎么工作的。 原文系列链接：PHP kernel - Inside PHP PHP的奥秘","tags":[]},{"title":"我有一个博客啦！","date":"2016-03-03T08:48:58.000Z","path":"2016/03/03/e6-88-91-e6-9c-89-e4-b8-80-e4-b8-aa-e5-8d-9a-e5-ae-a2-e5-95-a6-ef-bc-81/","text":"3月注定是最让人激动的。因为实习招聘来了！ 我才发现笔试要考的各种算法，操作系统，计算机组成原理我都没去复习。有点方～ 不过。第一份简历的完成、网投。让我回顾了一次大学三年的生活。确实让我热血沸腾。也让我决定建一个博客。 在我的第一次博客里面，我记下到9月秋招前的计划。 1、3月积极去参加各种笔试，有机会面试就更好啦。提前感受招聘的气息（能不能有实习机会没有关系）。 2、开始并坚持写博客（我做到了开始。L.O.L）。 3、在github上面托管一个自己的项目（内容应该是自己的php框架）。 记于2016 3.3","tags":[]}]